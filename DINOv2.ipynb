{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cdb250d4-6b50-4ec6-b9ec-76af00144906",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: timm in c:\\users\\91850\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (1.0.22)\n",
      "Requirement already satisfied: albumentations in c:\\users\\91850\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (2.0.8)\n",
      "Requirement already satisfied: efficientnet_pytorch in c:\\users\\91850\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (0.7.1)\n",
      "Requirement already satisfied: torch in c:\\users\\91850\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (2.7.1+cu118)\n",
      "Requirement already satisfied: torchvision in c:\\users\\91850\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (0.22.1+cu118)\n",
      "Requirement already satisfied: tqdm in c:\\users\\91850\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (4.67.1)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\91850\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (1.6.0)\n",
      "Requirement already satisfied: pandas in c:\\users\\91850\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (2.2.3)\n",
      "Requirement already satisfied: numpy in c:\\users\\91850\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (2.2.6)\n",
      "Requirement already satisfied: pillow in c:\\users\\91850\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (10.1.0)\n",
      "Requirement already satisfied: pyyaml in c:\\users\\91850\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from timm) (6.0.2)\n",
      "Requirement already satisfied: huggingface_hub in c:\\users\\91850\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from timm) (0.36.0)\n",
      "Requirement already satisfied: safetensors in c:\\users\\91850\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from timm) (0.5.3)\n",
      "Requirement already satisfied: scipy>=1.10.0 in c:\\users\\91850\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from albumentations) (1.14.1)\n",
      "Requirement already satisfied: pydantic>=2.9.2 in c:\\users\\91850\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from albumentations) (2.11.5)\n",
      "Requirement already satisfied: albucore==0.0.24 in c:\\users\\91850\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from albumentations) (0.0.24)\n",
      "Requirement already satisfied: opencv-python-headless>=4.9.0.80 in c:\\users\\91850\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from albumentations) (4.13.0.92)\n",
      "Requirement already satisfied: stringzilla>=3.10.4 in c:\\users\\91850\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from albucore==0.0.24->albumentations) (4.6.0)\n",
      "Requirement already satisfied: simsimd>=5.9.2 in c:\\users\\91850\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from albucore==0.0.24->albumentations) (6.5.12)\n",
      "Requirement already satisfied: filelock in c:\\users\\91850\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch) (3.18.0)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in c:\\users\\91850\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch) (4.12.2)\n",
      "Requirement already satisfied: sympy>=1.13.3 in c:\\users\\91850\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch) (1.14.0)\n",
      "Requirement already satisfied: networkx in c:\\users\\91850\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\91850\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch) (3.1.4)\n",
      "Requirement already satisfied: fsspec in c:\\users\\91850\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch) (2025.5.1)\n",
      "Requirement already satisfied: setuptools in c:\\users\\91850\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch) (80.9.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\91850\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tqdm) (0.4.6)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\91850\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from scikit-learn) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\91850\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from scikit-learn) (3.5.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\91850\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\91850\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pandas) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\91850\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pandas) (2024.2)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\91850\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pydantic>=2.9.2->albumentations) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in c:\\users\\91850\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pydantic>=2.9.2->albumentations) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in c:\\users\\91850\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pydantic>=2.9.2->albumentations) (0.4.1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\91850\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\91850\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
      "Requirement already satisfied: packaging>=20.9 in c:\\users\\91850\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from huggingface_hub->timm) (24.1)\n",
      "Requirement already satisfied: requests in c:\\users\\91850\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from huggingface_hub->timm) (2.32.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\91850\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from jinja2->torch) (2.1.5)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\91850\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests->huggingface_hub->timm) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\91850\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests->huggingface_hub->timm) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\91850\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests->huggingface_hub->timm) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\91850\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests->huggingface_hub->timm) (2024.8.30)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution ~orch (C:\\Users\\91850\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~orch (C:\\Users\\91850\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~orch (C:\\Users\\91850\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages)\n",
      "\n",
      "[notice] A new release of pip is available: 25.3 -> 26.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "# CELL 1: Install dependencies\n",
    "!pip install timm albumentations efficientnet_pytorch torch torchvision tqdm scikit-learn pandas numpy pillow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a1640626-bbe1-43b4-a088-d889b9f4fa9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "GPU : NVIDIA GeForce RTX 3070 Ti Laptop GPU\n",
      "VRAM: 8.6 GB\n",
      "\n",
      "Labels (14): ['Atelectasis', 'Consolidation', 'Infiltration', 'Pneumothorax', 'Edema', 'Emphysema', 'Fibrosis', 'Effusion', 'Pneumonia', 'PleuralThickening', 'Cardiomegaly', 'Nodule', 'Mass', 'Hernia']\n",
      "\n",
      "Data dir   : D:\\Major Project\\chest_xray_data\n",
      "CSV        : D:\\Major Project\\chest_xray_data\\Data_Entry_2017.csv\n",
      "B0  weights: D:\\Major Project\\best_balanced_effnet.pth\n",
      "B3  weights: D:\\Major Project\\best_efficientnet_b3.pth\n",
      "ViT weights: D:\\Major Project\\best_vit_base.pth\n"
     ]
    }
   ],
   "source": [
    "# CELL 2: Imports & Configuration\n",
    "import os, time, json, warnings, glob\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader, WeightedRandomSampler\n",
    "from torch.cuda.amp import autocast, GradScaler\n",
    "from torch.optim.lr_scheduler import OneCycleLR, CosineAnnealingWarmRestarts\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from PIL import Image\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "from tqdm import tqdm\n",
    "import timm\n",
    "\n",
    "# ── Device ──\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {DEVICE}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU : {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"VRAM: {torch.cuda.get_device_properties(0).total_memory/1e9:.1f} GB\")\n",
    "\n",
    "# ── Constants ──\n",
    "IMG_SIZE     = 224\n",
    "BATCH_SIZE   = 10        # safe for RTX 3070 Ti 8 GB\n",
    "NUM_WORKERS  = 0         # Windows → must be 0\n",
    "SEED         = 42\n",
    "LABEL_SMOOTH = 0.1\n",
    "\n",
    "LABELS = [\n",
    "    \"Atelectasis\",\"Consolidation\",\"Infiltration\",\"Pneumothorax\",\n",
    "    \"Edema\",\"Emphysema\",\"Fibrosis\",\"Effusion\",\"Pneumonia\",\n",
    "    \"PleuralThickening\",\"Cardiomegaly\",\"Nodule\",\"Mass\",\"Hernia\"\n",
    "]\n",
    "NUM_CLASSES = len(LABELS)\n",
    "\n",
    "# ── YOUR Paths ──\n",
    "BASE_DIR   = r\"D:\\Major Project\"\n",
    "DATA_DIR   = r\"D:\\Major Project\\chest_xray_data\"   # contains images_001 … images_012\n",
    "CSV_FILE   = os.path.join(DATA_DIR, \"Data_Entry_2017.csv\")\n",
    "TRAIN_LIST = os.path.join(DATA_DIR, \"train_val_list.txt\")\n",
    "TEST_LIST  = os.path.join(DATA_DIR, \"test_list.txt\")\n",
    "\n",
    "# ── Saved model paths (already trained) ──\n",
    "PATH_B0   = os.path.join(BASE_DIR, \"best_balanced_effnet.pth\")\n",
    "PATH_B3   = os.path.join(BASE_DIR, \"best_efficientnet_b3.pth\")\n",
    "PATH_VIT  = os.path.join(BASE_DIR, \"best_vit_base.pth\")\n",
    "PATH_DINO = os.path.join(BASE_DIR, \"best_ultimate_dinov2.pth\")  # will be saved here after Phase 7\n",
    "\n",
    "torch.manual_seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "print(f\"\\nLabels ({NUM_CLASSES}): {LABELS}\")\n",
    "print(f\"\\nData dir   : {DATA_DIR}\")\n",
    "print(f\"CSV        : {CSV_FILE}\")\n",
    "print(f\"B0  weights: {PATH_B0}\")\n",
    "print(f\"B3  weights: {PATH_B3}\")\n",
    "print(f\"ViT weights: {PATH_VIT}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "926cecb6-49f9-46f9-9d7f-50d9f3365a64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scanning: D:\\Major Project\\chest_xray_data\n",
      "Directory exists: True\n",
      "Top-level items found: 20\n",
      "  → ARXIV_V5_CHESTXRAY.pdf  (dir=False)\n",
      "  → BBox_List_2017.csv  (dir=False)\n",
      "  → Data_Entry_2017.csv  (dir=False)\n",
      "  → FAQ_CHESTXRAY.pdf  (dir=False)\n",
      "  → images_001  (dir=True)\n",
      "\n",
      "Total .png images found: 112120\n",
      "Sample entries:\n",
      "  00000001_000.png → D:\\Major Project\\chest_xray_data\\images_001\\images\\00000001_000.png\n",
      "  00000001_001.png → D:\\Major Project\\chest_xray_data\\images_001\\images\\00000001_001.png\n",
      "  00000001_002.png → D:\\Major Project\\chest_xray_data\\images_001\\images\\00000001_002.png\n"
     ]
    }
   ],
   "source": [
    "# CELL 3: Build filename → full_path lookup (Windows-safe, multi-method)\n",
    "\n",
    "import os, glob\n",
    "from pathlib import Path\n",
    "\n",
    "def build_image_map(data_dir):\n",
    "    img_map = {}\n",
    "    data_path = Path(data_dir)\n",
    "    \n",
    "    print(f\"Scanning: {data_path}\")\n",
    "    print(f\"Directory exists: {data_path.exists()}\")\n",
    "    \n",
    "    if not data_path.exists():\n",
    "        print(\"❌ ERROR: DATA_DIR does not exist! Check the path.\")\n",
    "        return img_map\n",
    "    \n",
    "    # List what's directly inside\n",
    "    top_level = list(data_path.iterdir())\n",
    "    print(f\"Top-level items found: {len(top_level)}\")\n",
    "    for item in top_level[:5]:\n",
    "        print(f\"  → {item.name}  (dir={item.is_dir()})\")\n",
    "    \n",
    "    # Method 1: Walk all subdirectories recursively\n",
    "    for root, dirs, files in os.walk(data_path):\n",
    "        for fname in files:\n",
    "            if fname.lower().endswith(\".png\"):\n",
    "                img_map[fname] = os.path.join(root, fname)\n",
    "    \n",
    "    print(f\"\\nTotal .png images found: {len(img_map)}\")\n",
    "    \n",
    "    if len(img_map) == 0:\n",
    "        # Debug: show what files ARE present\n",
    "        print(\"\\n⚠️  No PNGs found. Checking actual contents:\")\n",
    "        for root, dirs, files in os.walk(data_path):\n",
    "            if files:\n",
    "                print(f\"  Folder: {root}\")\n",
    "                print(f\"  Sample files: {files[:3]}\")\n",
    "                break\n",
    "    else:\n",
    "        # Show sample entries\n",
    "        sample = list(img_map.items())[:3]\n",
    "        print(\"Sample entries:\")\n",
    "        for k, v in sample:\n",
    "            print(f\"  {k} → {v}\")\n",
    "    \n",
    "    return img_map\n",
    "\n",
    "IMAGE_MAP = build_image_map(DATA_DIR)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1fe9ad44-2bd4-4896-bc69-7bd8c36b7807",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train :  73545 images\n",
      "Val   :  12979 images\n",
      "Test  :  25596 images\n"
     ]
    }
   ],
   "source": [
    "# CELL 4: Split Data_Entry_2017.csv using official train_val / test lists\n",
    "\n",
    "def load_dataframes():\n",
    "    df = pd.read_csv(CSV_FILE)\n",
    "    df.rename(columns={\"Image Index\": \"Image_Index\",\n",
    "                        \"Finding Labels\": \"Finding Labels\",\n",
    "                        \"Patient Age\": \"Patient_Age\",\n",
    "                        \"Patient Gender\": \"Patient_Gender\",\n",
    "                        \"View Position\": \"View_Position\",\n",
    "                        \"Follow-up #\": \"Follow-up #\"}, inplace=True)\n",
    "\n",
    "    with open(TRAIN_LIST) as f:\n",
    "        train_val_files = set(line.strip() for line in f)\n",
    "    with open(TEST_LIST) as f:\n",
    "        test_files = set(line.strip() for line in f)\n",
    "\n",
    "    df_trainval = df[df[\"Image_Index\"].isin(train_val_files)].reset_index(drop=True)\n",
    "    df_test     = df[df[\"Image_Index\"].isin(test_files)].reset_index(drop=True)\n",
    "\n",
    "    # 85/15 split of train_val → train / val\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    df_train, df_val = train_test_split(\n",
    "        df_trainval, test_size=0.15, random_state=SEED, shuffle=True\n",
    "    )\n",
    "    df_train = df_train.reset_index(drop=True)\n",
    "    df_val   = df_val.reset_index(drop=True)\n",
    "\n",
    "    print(f\"Train : {len(df_train):>6} images\")\n",
    "    print(f\"Val   : {len(df_val):>6} images\")\n",
    "    print(f\"Test  : {len(df_test):>6} images\")\n",
    "    return df_train, df_val, df_test\n",
    "\n",
    "DF_TRAIN, DF_VAL, DF_TEST = load_dataframes()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5ff0dae7-9714-44c7-af18-9c259913eb05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Dataset ready: 73545 samples\n",
      "  Dataset ready: 12979 samples\n",
      "  Dataset ready: 25596 samples\n",
      "\n",
      "Batches → Train:7355  Val:1298  Test:2560\n"
     ]
    }
   ],
   "source": [
    "# CELL 5: ChestXrayDataset, transforms, weighted sampler\n",
    "\n",
    "def build_transforms(train=True):\n",
    "    norm = A.Normalize(mean=(0.485,0.456,0.406), std=(0.229,0.224,0.225))\n",
    "    if train:\n",
    "        return A.Compose([\n",
    "            A.Resize(IMG_SIZE, IMG_SIZE),\n",
    "            A.HorizontalFlip(p=0.5),\n",
    "            A.RandomBrightnessContrast(0.15, 0.15, p=0.5),\n",
    "            A.ShiftScaleRotate(shift_limit=0.05, scale_limit=0.05,\n",
    "                               rotate_limit=5, p=0.4),\n",
    "            A.GaussNoise(var_limit=(5,20), p=0.2),\n",
    "            norm, ToTensorV2(),\n",
    "        ])\n",
    "    return A.Compose([A.Resize(IMG_SIZE, IMG_SIZE), norm, ToTensorV2()])\n",
    "\n",
    "\n",
    "class ChestXrayDataset(Dataset):\n",
    "    def __init__(self, df, image_map, transform=None):\n",
    "        # Keep only rows whose image file was actually found on disk\n",
    "        self.df        = df[df[\"Image_Index\"].isin(image_map)].reset_index(drop=True)\n",
    "        self.image_map = image_map\n",
    "        self.transform = transform\n",
    "        skipped = len(df) - len(self.df)\n",
    "        if skipped:\n",
    "            print(f\"  ⚠️  Skipped {skipped} rows (image not found on disk)\")\n",
    "        print(f\"  Dataset ready: {len(self.df)} samples\")\n",
    "\n",
    "    def _encode_metadata(self, row):\n",
    "        try:\n",
    "            age = float(str(row.get(\"Patient_Age\", 50)).replace(\"Y\",\"\").strip())\n",
    "        except:\n",
    "            age = 50.0\n",
    "        age    = np.clip(age, 0, 95) / 95.0\n",
    "        gender = {\"M\":0.0,\"F\":1.0}.get(str(row.get(\"Patient_Gender\",\"U\")).upper(), 0.5)\n",
    "        view   = {\"PA\":0.0,\"AP\":1.0}.get(str(row.get(\"View_Position\",\"U\")).upper(), 0.5)\n",
    "        follow = np.clip(float(row.get(\"Follow-up #\", 0)) / 10.0, 0, 1)\n",
    "        return np.array([age, gender, view, follow], dtype=np.float32)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row      = self.df.iloc[idx]\n",
    "        img_path = self.image_map[row[\"Image_Index\"]]\n",
    "        img      = np.array(Image.open(img_path).convert(\"RGB\"))\n",
    "        if self.transform:\n",
    "            img = self.transform(image=img)[\"image\"]\n",
    "\n",
    "        label_vec = np.zeros(NUM_CLASSES, dtype=np.float32)\n",
    "        for lbl in str(row.get(\"Finding Labels\",\"No Finding\")).split(\"|\"):\n",
    "            lbl = lbl.strip()\n",
    "            if lbl in LABELS:\n",
    "                label_vec[LABELS.index(lbl)] = 1.0\n",
    "\n",
    "        metadata = self._encode_metadata(row)\n",
    "        return img, torch.FloatTensor(label_vec), torch.FloatTensor(metadata)\n",
    "\n",
    "\n",
    "def build_weighted_sampler(df):\n",
    "    disease_w = {\n",
    "        \"Hernia\":50.0,\"Pneumonia\":15.0,\"Fibrosis\":8.0,\n",
    "        \"Edema\":7.0,\"Emphysema\":6.0,\"Cardiomegaly\":5.0,\n",
    "        \"PleuralThickening\":4.0,\"Nodule\":3.0,\"Mass\":3.0,\n",
    "        \"Consolidation\":2.5,\"Pneumothorax\":2.0,\n",
    "        \"Effusion\":1.5,\"Atelectasis\":1.2,\"Infiltration\":1.0,\n",
    "    }\n",
    "    sample_weights = []\n",
    "    for _, row in df.iterrows():\n",
    "        raw      = str(row.get(\"Finding Labels\",\"No Finding\"))\n",
    "        diseases = [l.strip() for l in raw.split(\"|\") if l.strip() in LABELS]\n",
    "        w = max((disease_w.get(d,1.0) for d in diseases), default=0.2)\n",
    "        sample_weights.append(w)\n",
    "    return WeightedRandomSampler(sample_weights,\n",
    "                                  num_samples=len(sample_weights),\n",
    "                                  replacement=True)\n",
    "\n",
    "\n",
    "def build_dataloaders():\n",
    "    train_ds = ChestXrayDataset(DF_TRAIN, IMAGE_MAP, build_transforms(True))\n",
    "    val_ds   = ChestXrayDataset(DF_VAL,   IMAGE_MAP, build_transforms(False))\n",
    "    test_ds  = ChestXrayDataset(DF_TEST,  IMAGE_MAP, build_transforms(False))\n",
    "\n",
    "    sampler  = build_weighted_sampler(DF_TRAIN)\n",
    "    train_dl = DataLoader(train_ds, batch_size=BATCH_SIZE, sampler=sampler,\n",
    "                          num_workers=NUM_WORKERS, pin_memory=True)\n",
    "    val_dl   = DataLoader(val_ds,   batch_size=BATCH_SIZE, shuffle=False,\n",
    "                          num_workers=NUM_WORKERS, pin_memory=True)\n",
    "    test_dl  = DataLoader(test_ds,  batch_size=BATCH_SIZE, shuffle=False,\n",
    "                          num_workers=NUM_WORKERS, pin_memory=True)\n",
    "    print(f\"\\nBatches → Train:{len(train_dl)}  Val:{len(val_dl)}  Test:{len(test_dl)}\")\n",
    "    return train_dl, val_dl, test_dl\n",
    "\n",
    "TRAIN_DL, VAL_DL, TEST_DL = build_dataloaders()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f549087b-967c-4386-b155-acd66e4bee85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class weights:\n",
      "  Atelectasis          0.01\n",
      "  Consolidation        0.04\n",
      "  Infiltration         0.01\n",
      "  Pneumothorax         0.04\n",
      "  Edema                0.08\n",
      "  Emphysema            0.08\n",
      "  Fibrosis             0.09\n",
      "  Effusion             0.01\n",
      "  Pneumonia            0.13\n",
      "  PleuralThickening    12.62\n",
      "  Cardiomegaly         0.07\n",
      "  Nodule               0.02\n",
      "  Mass                 0.03\n",
      "  Hernia               0.78\n"
     ]
    }
   ],
   "source": [
    "# CELL 6: Focal Loss with Label Smoothing + Class Weight Calculator\n",
    "\n",
    "def compute_class_weights(df):\n",
    "    counts = np.zeros(NUM_CLASSES)\n",
    "    for _, row in df.iterrows():\n",
    "        for lbl in str(row.get(\"Finding Labels\",\"\")).split(\"|\"):\n",
    "            lbl = lbl.strip()\n",
    "            if lbl in LABELS:\n",
    "                counts[LABELS.index(lbl)] += 1\n",
    "    freq    = np.clip(counts / len(df), 1e-4, 1.0)\n",
    "    weights = 1.0 / freq\n",
    "    weights = weights / weights.mean()\n",
    "    print(\"Class weights:\")\n",
    "    for l, w in zip(LABELS, weights):\n",
    "        print(f\"  {l:<20} {w:.2f}\")\n",
    "    return torch.FloatTensor(weights)\n",
    "\n",
    "\n",
    "class FocalLossWithSmoothing(nn.Module):\n",
    "    def __init__(self, class_weights, gamma=2.0, smoothing=0.1):\n",
    "        super().__init__()\n",
    "        self.class_weights = class_weights\n",
    "        self.gamma         = gamma\n",
    "        self.smoothing     = smoothing\n",
    "\n",
    "    def forward(self, logits, targets):\n",
    "        targets_smooth = targets * (1 - self.smoothing) + 0.5 * self.smoothing\n",
    "        bce   = F.binary_cross_entropy_with_logits(logits, targets_smooth, reduction=\"none\")\n",
    "        probs = torch.sigmoid(logits)\n",
    "        pt    = torch.where(targets > 0.5, probs, 1 - probs)\n",
    "        gammas = torch.full((NUM_CLASSES,), self.gamma, device=logits.device)\n",
    "        gammas[8]  = 3.0   # Pneumonia\n",
    "        gammas[11] = 2.5   # Nodule\n",
    "        focal_w = (1 - pt) ** gammas\n",
    "        return (focal_w * bce * self.class_weights.to(logits.device)).mean()\n",
    "\n",
    "\n",
    "CLASS_WEIGHTS = compute_class_weights(DF_TRAIN)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b0135b29-5418-43a1-8d8c-d6e9d01a2459",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CELL 7: All model architectures\n",
    "\n",
    "# ── EfficientNet-B0 ──\n",
    "class EfficientNetB0(nn.Module):\n",
    "    def __init__(self, num_classes=NUM_CLASSES, dropout=0.3):\n",
    "        super().__init__()\n",
    "        self.backbone = timm.create_model(\"efficientnet_b0\", pretrained=False, num_classes=0)\n",
    "        feat_dim = self.backbone.num_features\n",
    "        self.head = nn.Sequential(\n",
    "            nn.Linear(feat_dim, 512), nn.ReLU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(512, num_classes),\n",
    "        )\n",
    "    def forward(self, x, metadata=None):\n",
    "        return self.head(self.backbone(x))\n",
    "\n",
    "\n",
    "# ── EfficientNet-B3 ──\n",
    "class EfficientNetB3(nn.Module):\n",
    "    def __init__(self, num_classes=NUM_CLASSES, dropout=0.4):\n",
    "        super().__init__()\n",
    "        self.backbone = timm.create_model(\"efficientnet_b3\", pretrained=False, num_classes=0)\n",
    "        feat_dim = self.backbone.num_features\n",
    "        self.head = nn.Sequential(\n",
    "            nn.Linear(feat_dim, 512), nn.ReLU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(512, num_classes),\n",
    "        )\n",
    "    def forward(self, x, metadata=None):\n",
    "        return self.head(self.backbone(x))\n",
    "\n",
    "\n",
    "# ──────────────────────────────────────────────────────────────────\n",
    "# ViT-Base/16  — matches YOUR saved best_vit_base.pth exactly\n",
    "#\n",
    "# Saved keys reveal original structure:\n",
    "#   self.vit        → timm ViT backbone  (vit.blocks, vit.norm)\n",
    "#   self.classifier → Sequential head   (classifier.0, .2, .5)\n",
    "#\n",
    "# Head structure from keys:\n",
    "#   classifier.0  → Linear (LayerNorm not saved separately → it's Linear)\n",
    "#   classifier.2  → Linear\n",
    "#   classifier.5  → Linear   (3 linear layers with indices 0, 2, 5)\n",
    "#   → Sequential: Linear, act, Linear, Dropout, act, Linear  etc.\n",
    "# ──────────────────────────────────────────────────────────────────\n",
    "\n",
    "class ViTBase(nn.Module):\n",
    "    def __init__(self, num_classes=NUM_CLASSES, dropout=0.3):\n",
    "        super().__init__()\n",
    "        self.vit = timm.create_model(\n",
    "            \"vit_base_patch16_224\", pretrained=False, num_classes=0\n",
    "        )\n",
    "        feat_dim = self.vit.num_features  # 768\n",
    "\n",
    "        # Exactly 3 Linear layers at indices 0, 2, 5\n",
    "        # Sequential: Linear(768,512), GELU, Linear(512,256), Dropout, GELU, Linear(256,14)\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(feat_dim, 512),   # index 0\n",
    "            nn.GELU(),                  # index 1\n",
    "            nn.Linear(512, 256),        # index 2\n",
    "            nn.Dropout(dropout),        # index 3\n",
    "            nn.GELU(),                  # index 4\n",
    "            nn.Linear(256, num_classes) # index 5\n",
    "        )\n",
    "\n",
    "    def forward(self, x, metadata=None):\n",
    "        return self.classifier(self.vit(x))\n",
    "\n",
    "\n",
    "# ── DINOv2 Multi-Modal (Phase 7) ──\n",
    "class AnatomicalAttention(nn.Module):\n",
    "    def __init__(self, feat_dim=768):\n",
    "        super().__init__()\n",
    "        self.gate = nn.Sequential(\n",
    "            nn.Linear(feat_dim, feat_dim // 4), nn.ReLU(),\n",
    "            nn.Linear(feat_dim // 4, feat_dim), nn.Sigmoid(),\n",
    "        )\n",
    "    def forward(self, spatial_feats):\n",
    "        gap  = spatial_feats.mean(dim=[2, 3])\n",
    "        gate = self.gate(gap)\n",
    "        return gap * gate\n",
    "\n",
    "\n",
    "class DINOv2MultiModal(nn.Module):\n",
    "    def __init__(self, num_classes=NUM_CLASSES, freeze_blocks=8, dropout=0.3):\n",
    "        super().__init__()\n",
    "        self.backbone = torch.hub.load(\n",
    "            \"facebookresearch/dinov2\", \"dinov2_vitb14\", pretrained=True\n",
    "        )\n",
    "        for p in self.backbone.parameters():\n",
    "            p.requires_grad = False\n",
    "        for i in range(freeze_blocks, 12):\n",
    "            for p in self.backbone.blocks[i].parameters():\n",
    "                p.requires_grad = True\n",
    "        for p in self.backbone.norm.parameters():\n",
    "            p.requires_grad = True\n",
    "\n",
    "        feat_dim = self.backbone.embed_dim  # 768\n",
    "        self.attn = AnatomicalAttention(feat_dim)\n",
    "\n",
    "        self.meta_encoder = nn.Sequential(\n",
    "            nn.Linear(4, 64),   nn.ReLU(),\n",
    "            nn.Linear(64, 128), nn.ReLU(),\n",
    "            nn.Linear(128, 256), nn.ReLU(),\n",
    "        )\n",
    "        fuse_dim = feat_dim + 256  # 1024\n",
    "        self.fusion_head = nn.Sequential(\n",
    "            nn.LayerNorm(fuse_dim),\n",
    "            nn.Linear(fuse_dim, 512), nn.GELU(), nn.Dropout(dropout),\n",
    "            nn.Linear(512, 256),      nn.GELU(), nn.Dropout(dropout * 0.67),\n",
    "            nn.Linear(256, num_classes),\n",
    "        )\n",
    "\n",
    "    def forward(self, images, metadata):\n",
    "        B = images.shape[0]\n",
    "        out          = self.backbone.forward_features(images)\n",
    "        patch_tokens = out[\"x_norm_patchtokens\"]\n",
    "        H = W        = int(patch_tokens.shape[1] ** 0.5)\n",
    "        spatial      = patch_tokens.permute(0,2,1).reshape(B, -1, H, W)\n",
    "        cls_token    = out[\"x_norm_clstoken\"]\n",
    "        attended     = self.attn(spatial)\n",
    "        img_feat     = attended + cls_token\n",
    "        meta_feat    = self.meta_encoder(metadata)\n",
    "        fused        = torch.cat([img_feat, meta_feat], dim=1)\n",
    "        return self.fusion_head(fused)\n",
    "\n",
    "\n",
    "def count_params(model, name):\n",
    "    total    = sum(p.numel() for p in model.parameters()) / 1e6\n",
    "    trainable = sum(p.numel() for p in model.parameters() if p.requires_grad) / 1e6\n",
    "    print(f\"{name:<22} {total:.1f}M total | {trainable:.1f}M trainable\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "68bbc133-fa9a-4cea-b989-1538da644d90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CELL 7: Model definitions matching YOUR saved .pth files exactly\n",
    "# B0 & B3 → efficientnet_pytorch  (net._blocks keys)\n",
    "# ViT      → timm                  (backbone.blocks keys)\n",
    "\n",
    "import torch.nn as nn\n",
    "import timm\n",
    "from efficientnet_pytorch import EfficientNet\n",
    "\n",
    "# ──────────────────────────────────────────────\n",
    "# EfficientNet-B0  (efficientnet_pytorch style)\n",
    "# Keys: net._conv_stem, net._blocks, net._fc\n",
    "# ──────────────────────────────────────────────\n",
    "class EfficientNetB0(nn.Module):\n",
    "    def __init__(self, num_classes=NUM_CLASSES, dropout=0.3):\n",
    "        super().__init__()\n",
    "        self.net = EfficientNet.from_pretrained(\"efficientnet-b0\")\n",
    "        in_features = self.net._fc.in_features\n",
    "        self.net._fc = nn.Sequential(\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(in_features, num_classes),\n",
    "        )\n",
    "\n",
    "    def forward(self, x, metadata=None):\n",
    "        return self.net(x)\n",
    "\n",
    "\n",
    "# ──────────────────────────────────────────────\n",
    "# EfficientNet-B3  (efficientnet_pytorch style)\n",
    "# Keys: net._conv_stem, net._blocks, net._fc\n",
    "# ──────────────────────────────────────────────\n",
    "class EfficientNetB3(nn.Module):\n",
    "    def __init__(self, num_classes=NUM_CLASSES, dropout=0.4):\n",
    "        super().__init__()\n",
    "        self.net = EfficientNet.from_pretrained(\"efficientnet-b3\")\n",
    "        in_features = self.net._fc.in_features\n",
    "        self.net._fc = nn.Sequential(\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(in_features, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(512, num_classes),\n",
    "        )\n",
    "\n",
    "    def forward(self, x, metadata=None):\n",
    "        return self.net(x)\n",
    "\n",
    "class ViTBase(nn.Module):\n",
    "    def __init__(self, num_classes=NUM_CLASSES, dropout=0.3):\n",
    "        super().__init__()\n",
    "        self.vit = timm.create_model(\n",
    "            \"vit_base_patch16_224\", pretrained=False, num_classes=0\n",
    "        )\n",
    "        feat_dim = self.vit.num_features  # 768\n",
    "\n",
    "        # Exact structure decoded from checkpoint shapes:\n",
    "        # classifier.0 → LayerNorm(768)       weight shape (768,)\n",
    "        # classifier.1 → Dropout              no weights, index 1\n",
    "        # classifier.2 → Linear(768 → 512)    weight shape (512, 768)\n",
    "        # classifier.3 → GELU                 no weights, index 3\n",
    "        # classifier.4 → Dropout              no weights, index 4\n",
    "        # classifier.5 → Linear(512 → 14)     weight shape (14, 512)\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.LayerNorm(feat_dim),     # 0  ← weight shape (768,) ✅\n",
    "            nn.Dropout(dropout),        # 1\n",
    "            nn.Linear(feat_dim, 512),   # 2  ← weight shape (512, 768) ✅\n",
    "            nn.GELU(),                  # 3\n",
    "            nn.Dropout(dropout * 0.67), # 4\n",
    "            nn.Linear(512, num_classes) # 5  ← weight shape (14, 512) ✅\n",
    "        )\n",
    "\n",
    "    def forward(self, x, metadata=None):\n",
    "        return self.classifier(self.vit(x))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# ──────────────────────────────────────────────\n",
    "# DINOv2 Multi-Modal  (Phase 7 — trained fresh)\n",
    "# ──────────────────────────────────────────────\n",
    "class AnatomicalAttention(nn.Module):\n",
    "    def __init__(self, feat_dim=768):\n",
    "        super().__init__()\n",
    "        self.gate = nn.Sequential(\n",
    "            nn.Linear(feat_dim, feat_dim // 4), nn.ReLU(),\n",
    "            nn.Linear(feat_dim // 4, feat_dim), nn.Sigmoid(),\n",
    "        )\n",
    "    def forward(self, spatial_feats):\n",
    "        gap  = spatial_feats.mean(dim=[2, 3])\n",
    "        return gap * self.gate(gap)\n",
    "\n",
    "\n",
    "class DINOv2MultiModal(nn.Module):\n",
    "    def __init__(self, num_classes=NUM_CLASSES, freeze_blocks=8, dropout=0.3):\n",
    "        super().__init__()\n",
    "        self.backbone = torch.hub.load(\n",
    "            \"facebookresearch/dinov2\", \"dinov2_vitb14\", pretrained=True\n",
    "        )\n",
    "        for p in self.backbone.parameters():\n",
    "            p.requires_grad = False\n",
    "        for i in range(freeze_blocks, 12):\n",
    "            for p in self.backbone.blocks[i].parameters():\n",
    "                p.requires_grad = True\n",
    "        for p in self.backbone.norm.parameters():\n",
    "            p.requires_grad = True\n",
    "\n",
    "        feat_dim = self.backbone.embed_dim  # 768\n",
    "        self.attn = AnatomicalAttention(feat_dim)\n",
    "        self.meta_encoder = nn.Sequential(\n",
    "            nn.Linear(4, 64),    nn.ReLU(),\n",
    "            nn.Linear(64, 128),  nn.ReLU(),\n",
    "            nn.Linear(128, 256), nn.ReLU(),\n",
    "        )\n",
    "        self.fusion_head = nn.Sequential(\n",
    "            nn.LayerNorm(feat_dim + 256),\n",
    "            nn.Linear(feat_dim + 256, 512), nn.GELU(), nn.Dropout(dropout),\n",
    "            nn.Linear(512, 256),            nn.GELU(), nn.Dropout(dropout * 0.67),\n",
    "            nn.Linear(256, num_classes),\n",
    "        )\n",
    "\n",
    "    def forward(self, images, metadata):\n",
    "        B   = images.shape[0]\n",
    "        out = self.backbone.forward_features(images)\n",
    "        patch_tokens = out[\"x_norm_patchtokens\"]\n",
    "        H = W        = int(patch_tokens.shape[1] ** 0.5)\n",
    "        spatial      = patch_tokens.permute(0, 2, 1).reshape(B, -1, H, W)\n",
    "        cls_token    = out[\"x_norm_clstoken\"]\n",
    "        img_feat     = self.attn(spatial) + cls_token\n",
    "        meta_feat    = self.meta_encoder(metadata)\n",
    "        return self.fusion_head(torch.cat([img_feat, meta_feat], dim=1))\n",
    "\n",
    "\n",
    "def count_params(model, name):\n",
    "    total     = sum(p.numel() for p in model.parameters()) / 1e6\n",
    "    trainable = sum(p.numel() for p in model.parameters() if p.requires_grad) / 1e6\n",
    "    print(f\"{name:<25} {total:.1f}M total | {trainable:.1f}M trainable\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a860c8fd-c97b-42c4-8d42-df6ba29b0ac4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== ALL ViT checkpoint keys ===\n",
      "  vit.cls_token                                 shape: (1, 1, 768)\n",
      "  vit.pos_embed                                 shape: (1, 197, 768)\n",
      "  vit.patch_embed.proj.weight                   shape: (768, 3, 16, 16)\n",
      "  vit.patch_embed.proj.bias                     shape: (768,)\n",
      "  vit.blocks.0.norm1.weight                     shape: (768,)\n",
      "  vit.blocks.0.norm1.bias                       shape: (768,)\n",
      "  vit.blocks.0.attn.qkv.weight                  shape: (2304, 768)\n",
      "  vit.blocks.0.attn.qkv.bias                    shape: (2304,)\n",
      "  vit.blocks.0.attn.proj.weight                 shape: (768, 768)\n",
      "  vit.blocks.0.attn.proj.bias                   shape: (768,)\n",
      "  vit.blocks.0.norm2.weight                     shape: (768,)\n",
      "  vit.blocks.0.norm2.bias                       shape: (768,)\n",
      "  vit.blocks.0.mlp.fc1.weight                   shape: (3072, 768)\n",
      "  vit.blocks.0.mlp.fc1.bias                     shape: (3072,)\n",
      "  vit.blocks.0.mlp.fc2.weight                   shape: (768, 3072)\n",
      "  vit.blocks.0.mlp.fc2.bias                     shape: (768,)\n",
      "  vit.blocks.1.norm1.weight                     shape: (768,)\n",
      "  vit.blocks.1.norm1.bias                       shape: (768,)\n",
      "  vit.blocks.1.attn.qkv.weight                  shape: (2304, 768)\n",
      "  vit.blocks.1.attn.qkv.bias                    shape: (2304,)\n",
      "  vit.blocks.1.attn.proj.weight                 shape: (768, 768)\n",
      "  vit.blocks.1.attn.proj.bias                   shape: (768,)\n",
      "  vit.blocks.1.norm2.weight                     shape: (768,)\n",
      "  vit.blocks.1.norm2.bias                       shape: (768,)\n",
      "  vit.blocks.1.mlp.fc1.weight                   shape: (3072, 768)\n",
      "  vit.blocks.1.mlp.fc1.bias                     shape: (3072,)\n",
      "  vit.blocks.1.mlp.fc2.weight                   shape: (768, 3072)\n",
      "  vit.blocks.1.mlp.fc2.bias                     shape: (768,)\n",
      "  vit.blocks.2.norm1.weight                     shape: (768,)\n",
      "  vit.blocks.2.norm1.bias                       shape: (768,)\n",
      "  vit.blocks.2.attn.qkv.weight                  shape: (2304, 768)\n",
      "  vit.blocks.2.attn.qkv.bias                    shape: (2304,)\n",
      "  vit.blocks.2.attn.proj.weight                 shape: (768, 768)\n",
      "  vit.blocks.2.attn.proj.bias                   shape: (768,)\n",
      "  vit.blocks.2.norm2.weight                     shape: (768,)\n",
      "  vit.blocks.2.norm2.bias                       shape: (768,)\n",
      "  vit.blocks.2.mlp.fc1.weight                   shape: (3072, 768)\n",
      "  vit.blocks.2.mlp.fc1.bias                     shape: (3072,)\n",
      "  vit.blocks.2.mlp.fc2.weight                   shape: (768, 3072)\n",
      "  vit.blocks.2.mlp.fc2.bias                     shape: (768,)\n",
      "  vit.blocks.3.norm1.weight                     shape: (768,)\n",
      "  vit.blocks.3.norm1.bias                       shape: (768,)\n",
      "  vit.blocks.3.attn.qkv.weight                  shape: (2304, 768)\n",
      "  vit.blocks.3.attn.qkv.bias                    shape: (2304,)\n",
      "  vit.blocks.3.attn.proj.weight                 shape: (768, 768)\n",
      "  vit.blocks.3.attn.proj.bias                   shape: (768,)\n",
      "  vit.blocks.3.norm2.weight                     shape: (768,)\n",
      "  vit.blocks.3.norm2.bias                       shape: (768,)\n",
      "  vit.blocks.3.mlp.fc1.weight                   shape: (3072, 768)\n",
      "  vit.blocks.3.mlp.fc1.bias                     shape: (3072,)\n",
      "  vit.blocks.3.mlp.fc2.weight                   shape: (768, 3072)\n",
      "  vit.blocks.3.mlp.fc2.bias                     shape: (768,)\n",
      "  vit.blocks.4.norm1.weight                     shape: (768,)\n",
      "  vit.blocks.4.norm1.bias                       shape: (768,)\n",
      "  vit.blocks.4.attn.qkv.weight                  shape: (2304, 768)\n",
      "  vit.blocks.4.attn.qkv.bias                    shape: (2304,)\n",
      "  vit.blocks.4.attn.proj.weight                 shape: (768, 768)\n",
      "  vit.blocks.4.attn.proj.bias                   shape: (768,)\n",
      "  vit.blocks.4.norm2.weight                     shape: (768,)\n",
      "  vit.blocks.4.norm2.bias                       shape: (768,)\n",
      "  vit.blocks.4.mlp.fc1.weight                   shape: (3072, 768)\n",
      "  vit.blocks.4.mlp.fc1.bias                     shape: (3072,)\n",
      "  vit.blocks.4.mlp.fc2.weight                   shape: (768, 3072)\n",
      "  vit.blocks.4.mlp.fc2.bias                     shape: (768,)\n",
      "  vit.blocks.5.norm1.weight                     shape: (768,)\n",
      "  vit.blocks.5.norm1.bias                       shape: (768,)\n",
      "  vit.blocks.5.attn.qkv.weight                  shape: (2304, 768)\n",
      "  vit.blocks.5.attn.qkv.bias                    shape: (2304,)\n",
      "  vit.blocks.5.attn.proj.weight                 shape: (768, 768)\n",
      "  vit.blocks.5.attn.proj.bias                   shape: (768,)\n",
      "  vit.blocks.5.norm2.weight                     shape: (768,)\n",
      "  vit.blocks.5.norm2.bias                       shape: (768,)\n",
      "  vit.blocks.5.mlp.fc1.weight                   shape: (3072, 768)\n",
      "  vit.blocks.5.mlp.fc1.bias                     shape: (3072,)\n",
      "  vit.blocks.5.mlp.fc2.weight                   shape: (768, 3072)\n",
      "  vit.blocks.5.mlp.fc2.bias                     shape: (768,)\n",
      "  vit.blocks.6.norm1.weight                     shape: (768,)\n",
      "  vit.blocks.6.norm1.bias                       shape: (768,)\n",
      "  vit.blocks.6.attn.qkv.weight                  shape: (2304, 768)\n",
      "  vit.blocks.6.attn.qkv.bias                    shape: (2304,)\n",
      "  vit.blocks.6.attn.proj.weight                 shape: (768, 768)\n",
      "  vit.blocks.6.attn.proj.bias                   shape: (768,)\n",
      "  vit.blocks.6.norm2.weight                     shape: (768,)\n",
      "  vit.blocks.6.norm2.bias                       shape: (768,)\n",
      "  vit.blocks.6.mlp.fc1.weight                   shape: (3072, 768)\n",
      "  vit.blocks.6.mlp.fc1.bias                     shape: (3072,)\n",
      "  vit.blocks.6.mlp.fc2.weight                   shape: (768, 3072)\n",
      "  vit.blocks.6.mlp.fc2.bias                     shape: (768,)\n",
      "  vit.blocks.7.norm1.weight                     shape: (768,)\n",
      "  vit.blocks.7.norm1.bias                       shape: (768,)\n",
      "  vit.blocks.7.attn.qkv.weight                  shape: (2304, 768)\n",
      "  vit.blocks.7.attn.qkv.bias                    shape: (2304,)\n",
      "  vit.blocks.7.attn.proj.weight                 shape: (768, 768)\n",
      "  vit.blocks.7.attn.proj.bias                   shape: (768,)\n",
      "  vit.blocks.7.norm2.weight                     shape: (768,)\n",
      "  vit.blocks.7.norm2.bias                       shape: (768,)\n",
      "  vit.blocks.7.mlp.fc1.weight                   shape: (3072, 768)\n",
      "  vit.blocks.7.mlp.fc1.bias                     shape: (3072,)\n",
      "  vit.blocks.7.mlp.fc2.weight                   shape: (768, 3072)\n",
      "  vit.blocks.7.mlp.fc2.bias                     shape: (768,)\n",
      "  vit.blocks.8.norm1.weight                     shape: (768,)\n",
      "  vit.blocks.8.norm1.bias                       shape: (768,)\n",
      "  vit.blocks.8.attn.qkv.weight                  shape: (2304, 768)\n",
      "  vit.blocks.8.attn.qkv.bias                    shape: (2304,)\n",
      "  vit.blocks.8.attn.proj.weight                 shape: (768, 768)\n",
      "  vit.blocks.8.attn.proj.bias                   shape: (768,)\n",
      "  vit.blocks.8.norm2.weight                     shape: (768,)\n",
      "  vit.blocks.8.norm2.bias                       shape: (768,)\n",
      "  vit.blocks.8.mlp.fc1.weight                   shape: (3072, 768)\n",
      "  vit.blocks.8.mlp.fc1.bias                     shape: (3072,)\n",
      "  vit.blocks.8.mlp.fc2.weight                   shape: (768, 3072)\n",
      "  vit.blocks.8.mlp.fc2.bias                     shape: (768,)\n",
      "  vit.blocks.9.norm1.weight                     shape: (768,)\n",
      "  vit.blocks.9.norm1.bias                       shape: (768,)\n",
      "  vit.blocks.9.attn.qkv.weight                  shape: (2304, 768)\n",
      "  vit.blocks.9.attn.qkv.bias                    shape: (2304,)\n",
      "  vit.blocks.9.attn.proj.weight                 shape: (768, 768)\n",
      "  vit.blocks.9.attn.proj.bias                   shape: (768,)\n",
      "  vit.blocks.9.norm2.weight                     shape: (768,)\n",
      "  vit.blocks.9.norm2.bias                       shape: (768,)\n",
      "  vit.blocks.9.mlp.fc1.weight                   shape: (3072, 768)\n",
      "  vit.blocks.9.mlp.fc1.bias                     shape: (3072,)\n",
      "  vit.blocks.9.mlp.fc2.weight                   shape: (768, 3072)\n",
      "  vit.blocks.9.mlp.fc2.bias                     shape: (768,)\n",
      "  vit.blocks.10.norm1.weight                    shape: (768,)\n",
      "  vit.blocks.10.norm1.bias                      shape: (768,)\n",
      "  vit.blocks.10.attn.qkv.weight                 shape: (2304, 768)\n",
      "  vit.blocks.10.attn.qkv.bias                   shape: (2304,)\n",
      "  vit.blocks.10.attn.proj.weight                shape: (768, 768)\n",
      "  vit.blocks.10.attn.proj.bias                  shape: (768,)\n",
      "  vit.blocks.10.norm2.weight                    shape: (768,)\n",
      "  vit.blocks.10.norm2.bias                      shape: (768,)\n",
      "  vit.blocks.10.mlp.fc1.weight                  shape: (3072, 768)\n",
      "  vit.blocks.10.mlp.fc1.bias                    shape: (3072,)\n",
      "  vit.blocks.10.mlp.fc2.weight                  shape: (768, 3072)\n",
      "  vit.blocks.10.mlp.fc2.bias                    shape: (768,)\n",
      "  vit.blocks.11.norm1.weight                    shape: (768,)\n",
      "  vit.blocks.11.norm1.bias                      shape: (768,)\n",
      "  vit.blocks.11.attn.qkv.weight                 shape: (2304, 768)\n",
      "  vit.blocks.11.attn.qkv.bias                   shape: (2304,)\n",
      "  vit.blocks.11.attn.proj.weight                shape: (768, 768)\n",
      "  vit.blocks.11.attn.proj.bias                  shape: (768,)\n",
      "  vit.blocks.11.norm2.weight                    shape: (768,)\n",
      "  vit.blocks.11.norm2.bias                      shape: (768,)\n",
      "  vit.blocks.11.mlp.fc1.weight                  shape: (3072, 768)\n",
      "  vit.blocks.11.mlp.fc1.bias                    shape: (3072,)\n",
      "  vit.blocks.11.mlp.fc2.weight                  shape: (768, 3072)\n",
      "  vit.blocks.11.mlp.fc2.bias                    shape: (768,)\n",
      "  vit.norm.weight                               shape: (768,)\n",
      "  vit.norm.bias                                 shape: (768,)\n",
      "  classifier.0.weight                           shape: (768,)\n",
      "  classifier.0.bias                             shape: (768,)\n",
      "  classifier.2.weight                           shape: (512, 768)\n",
      "  classifier.2.bias                             shape: (512,)\n",
      "  classifier.5.weight                           shape: (14, 512)\n",
      "  classifier.5.bias                             shape: (14,)\n"
     ]
    }
   ],
   "source": [
    "# KEY INSPECTOR — run once to see exact ViT saved structure\n",
    "ckpt = torch.load(PATH_VIT, map_location=\"cpu\")\n",
    "if isinstance(ckpt, dict) and \"model_state_dict\" in ckpt:\n",
    "    ckpt = ckpt[\"model_state_dict\"]\n",
    "elif isinstance(ckpt, dict) and \"state_dict\" in ckpt:\n",
    "    ckpt = ckpt[\"state_dict\"]\n",
    "\n",
    "print(\"=== ALL ViT checkpoint keys ===\")\n",
    "for k, v in ckpt.items():\n",
    "    print(f\"  {k:<45} shape: {tuple(v.shape)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3018ef7c-dac5-4d86-9907-5ffd74c98979",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading trained models...\n",
      "\n",
      "Loaded pretrained weights for efficientnet-b0\n",
      "\n",
      "EfficientNet-B0\n",
      "  Saved keys (first 3) : ['net._conv_stem.weight', 'net._bn0.weight', 'net._bn0.bias']\n",
      "  Model keys (first 3) : ['net._conv_stem.weight', 'net._bn0.weight', 'net._bn0.bias']\n",
      "  ✅ Loaded successfully\n",
      "EfficientNet-B0           4.0M total | 4.0M trainable\n",
      "Loaded pretrained weights for efficientnet-b3\n",
      "\n",
      "EfficientNet-B3\n",
      "  Saved keys (first 3) : ['net._conv_stem.weight', 'net._bn0.weight', 'net._bn0.bias']\n",
      "  Model keys (first 3) : ['net._conv_stem.weight', 'net._bn0.weight', 'net._bn0.bias']\n",
      "  ✅ Loaded successfully\n",
      "EfficientNet-B3           11.5M total | 11.5M trainable\n",
      "\n",
      "ViT-Base/16\n",
      "  Saved keys (first 3) : ['vit.cls_token', 'vit.pos_embed', 'vit.patch_embed.proj.weight']\n",
      "  Model keys (first 3) : ['vit.cls_token', 'vit.pos_embed', 'vit.patch_embed.proj.weight']\n",
      "  ✅ Loaded successfully\n",
      "ViT-Base/16               86.2M total | 86.2M trainable\n",
      "\n",
      "✅ All three models loaded.\n"
     ]
    }
   ],
   "source": [
    "# CELL 8: Load pre-trained B0, B3, ViT — with auto key-inspection before loading\n",
    "\n",
    "def inspect_and_load(model, path, name):\n",
    "    \"\"\"\n",
    "    Inspects the first 3 keys of the saved checkpoint to confirm\n",
    "    library match, then loads. Raises a clear message if mismatch.\n",
    "    \"\"\"\n",
    "    ckpt = torch.load(path, map_location=DEVICE)\n",
    "\n",
    "    # Handle if saved as {\"model_state_dict\": ...} or {\"state_dict\": ...}\n",
    "    if isinstance(ckpt, dict):\n",
    "        if \"model_state_dict\" in ckpt:\n",
    "            ckpt = ckpt[\"model_state_dict\"]\n",
    "        elif \"state_dict\" in ckpt:\n",
    "            ckpt = ckpt[\"state_dict\"]\n",
    "        # else assume it IS the state_dict already\n",
    "\n",
    "    saved_keys   = list(ckpt.keys())[:3]\n",
    "    model_keys   = list(model.state_dict().keys())[:3]\n",
    "    print(f\"\\n{name}\")\n",
    "    print(f\"  Saved keys (first 3) : {saved_keys}\")\n",
    "    print(f\"  Model keys (first 3) : {model_keys}\")\n",
    "\n",
    "    result = model.load_state_dict(ckpt, strict=True)\n",
    "    print(f\"  ✅ Loaded successfully\")\n",
    "    return model\n",
    "\n",
    "\n",
    "print(\"Loading trained models...\\n\")\n",
    "\n",
    "model_b0 = EfficientNetB0().to(DEVICE)\n",
    "model_b0 = inspect_and_load(model_b0, PATH_B0, \"EfficientNet-B0\")\n",
    "model_b0.eval()\n",
    "count_params(model_b0, \"EfficientNet-B0\")\n",
    "\n",
    "model_b3 = EfficientNetB3().to(DEVICE)\n",
    "model_b3 = inspect_and_load(model_b3, PATH_B3, \"EfficientNet-B3\")\n",
    "model_b3.eval()\n",
    "count_params(model_b3, \"EfficientNet-B3\")\n",
    "\n",
    "model_vit = ViTBase().to(DEVICE)\n",
    "model_vit = inspect_and_load(model_vit, PATH_VIT, \"ViT-Base/16\")\n",
    "model_vit.eval()\n",
    "count_params(model_vit, \"ViT-Base/16\")\n",
    "\n",
    "print(\"\\n✅ All three models loaded.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "d30f5baa-4f23-4b24-ab7d-ab6914c2bf46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Safe AUC functions defined. Re-running evaluations...\n",
      "\n",
      "Evaluating EfficientNet-B0...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  Eval EfficientNet-B0: 100%|███████████████████████████████████| 2560/2560 [28:06<00:00,  1.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ⚠️  Skipping PleuralThickening — only class [0.] present in split\n",
      "\n",
      "=======================================================\n",
      "  EfficientNet-B0  —  Test AUC (macro): 0.8293\n",
      "=======================================================\n",
      "  Atelectasis            0.7106\n",
      "  Consolidation          0.7463\n",
      "  Infiltration           0.7004\n",
      "  Pneumothorax           0.8752  ✅\n",
      "  Edema                  0.8988  ✅\n",
      "  Emphysema              0.9347  ✅\n",
      "  Fibrosis               0.9107  ✅\n",
      "  Effusion               0.7849\n",
      "  Pneumonia              0.8687  ✅\n",
      "  PleuralThickening       N/A  (single class)\n",
      "  Cardiomegaly           0.9142  ✅\n",
      "  Nodule                 0.6995  ⚠️ \n",
      "  Mass                   0.7583\n",
      "  Hernia                 0.9783  ✅\n",
      "\n",
      "Evaluating EfficientNet-B3...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  Eval EfficientNet-B3: 100%|███████████████████████████████████| 2560/2560 [27:12<00:00,  1.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ⚠️  Skipping PleuralThickening — only class [0.] present in split\n",
      "\n",
      "=======================================================\n",
      "  EfficientNet-B3  —  Test AUC (macro): 0.8350\n",
      "=======================================================\n",
      "  Atelectasis            0.7096\n",
      "  Consolidation          0.7448\n",
      "  Infiltration           0.6867  ⚠️ \n",
      "  Pneumothorax           0.8780  ✅\n",
      "  Edema                  0.9207  ✅\n",
      "  Emphysema              0.9474  ✅\n",
      "  Fibrosis               0.9365  ✅\n",
      "  Effusion               0.7766\n",
      "  Pneumonia              0.8834  ✅\n",
      "  PleuralThickening       N/A  (single class)\n",
      "  Cardiomegaly           0.9192  ✅\n",
      "  Nodule                 0.7100\n",
      "  Mass                   0.7579\n",
      "  Hernia                 0.9843  ✅\n",
      "\n",
      "Evaluating ViT-Base/16...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  Eval ViT-Base/16: 100%|███████████████████████████████████████| 2560/2560 [25:30<00:00,  1.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ⚠️  Skipping PleuralThickening — only class [0.] present in split\n",
      "\n",
      "=======================================================\n",
      "  ViT-Base/16  —  Test AUC (macro): 0.8379\n",
      "=======================================================\n",
      "  Atelectasis            0.7324\n",
      "  Consolidation          0.7590\n",
      "  Infiltration           0.6749  ⚠️ \n",
      "  Pneumothorax           0.8852  ✅\n",
      "  Edema                  0.9067  ✅\n",
      "  Emphysema              0.9386  ✅\n",
      "  Fibrosis               0.9113  ✅\n",
      "  Effusion               0.7945\n",
      "  Pneumonia              0.8666  ✅\n",
      "  PleuralThickening       N/A  (single class)\n",
      "  Cardiomegaly           0.9239  ✅\n",
      "  Nodule                 0.7245\n",
      "  Mass                   0.7988\n",
      "  Hernia                 0.9757  ✅\n",
      "\n",
      "=======================================================\n",
      "  EfficientNet-B0  AUC: 0.8293\n",
      "  EfficientNet-B3  AUC: 0.8350\n",
      "  ViT-Base/16      AUC: 0.8379\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# CELL 9 (FIXED): Handle NaN per-class AUC from single-class columns\n",
    "\n",
    "def safe_roc_auc(y_true, y_pred, average=None):\n",
    "    \"\"\"\n",
    "    Computes ROC AUC safely — skips classes with only one label present.\n",
    "    Returns per-class array with np.nan for invalid classes,\n",
    "    and macro average computed only over valid classes.\n",
    "    \"\"\"\n",
    "    n_classes  = y_true.shape[1]\n",
    "    per_class  = np.full(n_classes, np.nan)\n",
    "\n",
    "    for i in range(n_classes):\n",
    "        unique = np.unique(y_true[:, i])\n",
    "        if len(unique) < 2:\n",
    "            print(f\"  ⚠️  Skipping {LABELS[i]} — only class {unique} present in split\")\n",
    "            continue\n",
    "        per_class[i] = roc_auc_score(y_true[:, i], y_pred[:, i])\n",
    "\n",
    "    valid_mask  = ~np.isnan(per_class)\n",
    "    macro_auc   = float(np.mean(per_class[valid_mask]))\n",
    "    return macro_auc, per_class\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def evaluate_model(model, loader, label=\"Model\"):\n",
    "    model.eval()\n",
    "    all_labels, all_preds = [], []\n",
    "    for x, y, meta in tqdm(loader, desc=f\"  Eval {label}\", ncols=100):\n",
    "        x = x.to(DEVICE)\n",
    "        with torch.cuda.amp.autocast():\n",
    "            logits = model(x, None)\n",
    "        all_labels.append(y.numpy())\n",
    "        all_preds.append(torch.sigmoid(logits).cpu().float().numpy())\n",
    "\n",
    "    y_true = np.vstack(all_labels)\n",
    "    y_pred = np.vstack(all_preds)\n",
    "\n",
    "    auc_macro, per_class = safe_roc_auc(y_true, y_pred)\n",
    "\n",
    "    print(f\"\\n{'='*55}\")\n",
    "    print(f\"  {label}  —  Test AUC (macro): {auc_macro:.4f}\")\n",
    "    print(f\"{'='*55}\")\n",
    "    for l, a in zip(LABELS, per_class):\n",
    "        if np.isnan(a):\n",
    "            print(f\"  {l:<22}  N/A  (single class)\")\n",
    "        else:\n",
    "            flag = \"  ⚠️ \" if a < 0.70 else (\"  ✅\" if a >= 0.85 else \"\")\n",
    "            print(f\"  {l:<22} {a:.4f}{flag}\")\n",
    "\n",
    "    return y_pred, y_true, auc_macro, per_class\n",
    "\n",
    "\n",
    "# Also fix evaluate_model_with_meta in Cell 11\n",
    "@torch.no_grad()\n",
    "def evaluate_model_with_meta(model, loader, label=\"Model\"):\n",
    "    model.eval()\n",
    "    all_labels, all_preds = [], []\n",
    "    for x, y, meta in tqdm(loader, desc=f\"  Eval {label}\", ncols=100):\n",
    "        x, meta = x.to(DEVICE), meta.to(DEVICE)\n",
    "        with torch.cuda.amp.autocast():\n",
    "            logits = model(x, meta)\n",
    "        all_labels.append(y.numpy())\n",
    "        all_preds.append(torch.sigmoid(logits).cpu().float().numpy())\n",
    "\n",
    "    y_true = np.vstack(all_labels)\n",
    "    y_pred = np.vstack(all_preds)\n",
    "\n",
    "    auc_macro, per_class = safe_roc_auc(y_true, y_pred)\n",
    "\n",
    "    print(f\"\\n{'='*55}\")\n",
    "    print(f\"  {label}  —  Test AUC (macro): {auc_macro:.4f}\")\n",
    "    print(f\"{'='*55}\")\n",
    "    for l, a in zip(LABELS, per_class):\n",
    "        if np.isnan(a):\n",
    "            print(f\"  {l:<22}  N/A  (single class)\")\n",
    "        else:\n",
    "            flag = \"  ⚠️ \" if a < 0.70 else (\"  ✅\" if a >= 0.85 else \"\")\n",
    "            print(f\"  {l:<22} {a:.4f}{flag}\")\n",
    "\n",
    "    return y_pred, y_true, auc_macro, per_class\n",
    "\n",
    "\n",
    "# Also fix val_epoch in Cell 11\n",
    "def val_epoch(model, loader, loss_fn):\n",
    "    model.eval()\n",
    "    total_loss, all_labels, all_preds = 0.0, [], []\n",
    "    with torch.no_grad():\n",
    "        for x, y, meta in tqdm(loader, desc=\"  Validate\", ncols=110):\n",
    "            x, y, meta = x.to(DEVICE), y.to(DEVICE), meta.to(DEVICE)\n",
    "            with torch.cuda.amp.autocast():\n",
    "                logits = model(x, meta)\n",
    "                loss   = loss_fn(logits, y)\n",
    "            total_loss += loss.item()\n",
    "            all_labels.append(y.cpu().numpy())\n",
    "            all_preds.append(torch.sigmoid(logits).cpu().float().numpy())\n",
    "    y_true = np.vstack(all_labels)\n",
    "    y_pred = np.vstack(all_preds)\n",
    "    auc, per_class = safe_roc_auc(y_true, y_pred)\n",
    "    return total_loss / len(loader), auc, per_class\n",
    "\n",
    "\n",
    "# Fix safe_roc_auc for ensemble cells (scalar input)\n",
    "def safe_roc_auc_ensemble(y_true, y_pred):\n",
    "    \"\"\"Same as safe_roc_auc but also handles the 3/4-way ensemble arrays.\"\"\"\n",
    "    n_classes = y_true.shape[1]\n",
    "    per_class = np.full(n_classes, np.nan)\n",
    "    for i in range(n_classes):\n",
    "        if len(np.unique(y_true[:, i])) < 2:\n",
    "            continue\n",
    "        per_class[i] = roc_auc_score(y_true[:, i], y_pred[:, i])\n",
    "    valid     = ~np.isnan(per_class)\n",
    "    macro_auc = float(np.mean(per_class[valid]))\n",
    "    return macro_auc, per_class\n",
    "\n",
    "print(\"✅ Safe AUC functions defined. Re-running evaluations...\\n\")\n",
    "\n",
    "# Re-run all 3 evaluations\n",
    "print(\"Evaluating EfficientNet-B0...\")\n",
    "b0_preds,  test_labels, b0_auc,  b0_pc  = evaluate_model(model_b0,  TEST_DL, \"EfficientNet-B0\")\n",
    "\n",
    "print(\"\\nEvaluating EfficientNet-B3...\")\n",
    "b3_preds,  _,           b3_auc,  b3_pc  = evaluate_model(model_b3,  TEST_DL, \"EfficientNet-B3\")\n",
    "\n",
    "print(\"\\nEvaluating ViT-Base/16...\")\n",
    "vit_preds, _,           vit_auc, vit_pc = evaluate_model(model_vit, TEST_DL, \"ViT-Base/16\")\n",
    "\n",
    "print(f\"\\n{'='*55}\")\n",
    "print(f\"  EfficientNet-B0  AUC: {b0_auc:.4f}\")\n",
    "print(f\"  EfficientNet-B3  AUC: {b3_auc:.4f}\")\n",
    "print(f\"  ViT-Base/16      AUC: {vit_auc:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f41cbc1a-5881-434d-9477-0af1a03784d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing 3-way ensemble weights...\n",
      "\n",
      "  B0=0.40  B3=0.30  ViT=0.30  →  AUC=0.8566  ← BEST\n",
      "  B0=0.50  B3=0.25  ViT=0.25  →  AUC=0.8546\n",
      "  B0=0.40  B3=0.20  ViT=0.40  →  AUC=0.8571  ← BEST\n",
      "  B0=0.33  B3=0.33  ViT=0.34  →  AUC=0.8575  ← BEST\n",
      "  B0=0.35  B3=0.25  ViT=0.40  →  AUC=0.8577  ← BEST\n",
      "  B0=0.45  B3=0.15  ViT=0.40  →  AUC=0.8561\n",
      "\n",
      "=======================================================\n",
      "  Best 3-Way Ensemble AUC : 0.8577\n",
      "  Weights → B0=0.35  B3=0.25  ViT=0.4\n",
      "=======================================================\n",
      "\n",
      "Per-class AUC (3-Way Ensemble):\n",
      "  Atelectasis            0.7427\n",
      "  Consolidation          0.7735\n",
      "  Infiltration           0.7080\n",
      "  Pneumothorax           0.8993  ✅\n",
      "  Edema                  0.9343  ✅\n",
      "  Emphysema              0.9599  ✅\n",
      "  Fibrosis               0.9463  ✅\n",
      "  Effusion               0.8111\n",
      "  Pneumonia              0.9021  ✅\n",
      "  PleuralThickening       N/A\n",
      "  Cardiomegaly           0.9445  ✅\n",
      "  Nodule                 0.7382\n",
      "  Mass                   0.8074\n",
      "  Hernia                 0.9831  ✅\n",
      "\n",
      "  Minority Avg AUC : 0.9451\n",
      "  Hernia                 0.9831\n",
      "  Pneumonia              0.9021\n",
      "  Edema                  0.9343\n",
      "  Emphysema              0.9599\n",
      "  Fibrosis               0.9463\n",
      "\n",
      "✅ 3-Way ensemble done — now re-run Cell 15.\n"
     ]
    }
   ],
   "source": [
    "# CELL 10 (catch-up): 3-Way Ensemble — run before Cell 15\n",
    "\n",
    "weight_configs_3 = [\n",
    "    (0.40, 0.30, 0.30),\n",
    "    (0.50, 0.25, 0.25),\n",
    "    (0.40, 0.20, 0.40),\n",
    "    (0.33, 0.33, 0.34),\n",
    "    (0.35, 0.25, 0.40),\n",
    "    (0.45, 0.15, 0.40),\n",
    "]\n",
    "\n",
    "best3_auc, best3_w, best3_preds = -1.0, None, None\n",
    "print(\"Testing 3-way ensemble weights...\\n\")\n",
    "\n",
    "for wb0, wb3, wvit in weight_configs_3:\n",
    "    ens      = wb0*b0_preds + wb3*b3_preds + wvit*vit_preds\n",
    "    auc, _   = safe_roc_auc(test_labels, ens)\n",
    "    auc_safe = auc if not np.isnan(auc) else 0.0\n",
    "    flag     = \"  ← BEST\" if auc_safe > best3_auc else \"\"\n",
    "    print(f\"  B0={wb0:.2f}  B3={wb3:.2f}  ViT={wvit:.2f}  →  AUC={auc_safe:.4f}{flag}\")\n",
    "    if auc_safe > best3_auc:\n",
    "        best3_auc, best3_w, best3_preds = auc_safe, (wb0, wb3, wvit), ens.copy()\n",
    "\n",
    "_, best3_pc  = safe_roc_auc(test_labels, best3_preds)\n",
    "m_aucs_3     = [best3_pc[LABELS.index(c)] for c in minority_classes]\n",
    "\n",
    "print(f\"\\n{'='*55}\")\n",
    "print(f\"  Best 3-Way Ensemble AUC : {best3_auc:.4f}\")\n",
    "print(f\"  Weights → B0={best3_w[0]}  B3={best3_w[1]}  ViT={best3_w[2]}\")\n",
    "print(f\"{'='*55}\")\n",
    "print(\"\\nPer-class AUC (3-Way Ensemble):\")\n",
    "for l, a in zip(LABELS, best3_pc):\n",
    "    if np.isnan(a):\n",
    "        print(f\"  {l:<22}  N/A\")\n",
    "    else:\n",
    "        flag = \"  ⚠️ \" if a < 0.70 else (\"  ✅\" if a >= 0.85 else \"\")\n",
    "        print(f\"  {l:<22} {a:.4f}{flag}\")\n",
    "\n",
    "print(f\"\\n  Minority Avg AUC : {np.nanmean(m_aucs_3):.4f}\")\n",
    "for c, a in zip(minority_classes, m_aucs_3):\n",
    "    print(f\"  {c:<22} {a:.4f}\" if not np.isnan(a) else f\"  {c:<22}  N/A\")\n",
    "\n",
    "print(\"\\n✅ 3-Way ensemble done — now re-run Cell 15.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cb0c1ae3-c8d7-4d41-8c9a-dda5291f0a91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ All helpers defined correctly with safe AUC.\n"
     ]
    }
   ],
   "source": [
    "# CELL 11 FIXED: All helpers with safe AUC — run before Cell 12\n",
    "\n",
    "def safe_roc_auc(y_true, y_pred):\n",
    "    \"\"\"Skips classes with only one label, returns valid macro AUC.\"\"\"\n",
    "    n_classes = y_true.shape[1]\n",
    "    per_class = np.full(n_classes, np.nan)\n",
    "    for i in range(n_classes):\n",
    "        if len(np.unique(y_true[:, i])) < 2:\n",
    "            continue\n",
    "        per_class[i] = roc_auc_score(y_true[:, i], y_pred[:, i])\n",
    "    valid     = ~np.isnan(per_class)\n",
    "    macro_auc = float(np.nanmean(per_class[valid]))\n",
    "    return macro_auc, per_class\n",
    "\n",
    "\n",
    "def train_epoch(model, loader, loss_fn, optimizer, scaler, scheduler, epoch):\n",
    "    model.train()\n",
    "    total_loss, all_labels, all_preds = 0.0, [], []\n",
    "    pbar = tqdm(loader, desc=f\"Epoch {epoch:02d} Train\", ncols=110)\n",
    "    for i, (x, y, meta) in enumerate(pbar):\n",
    "        x, y, meta = x.to(DEVICE), y.to(DEVICE), meta.to(DEVICE)\n",
    "        optimizer.zero_grad(set_to_none=True)\n",
    "        with torch.cuda.amp.autocast():\n",
    "            logits = model(x, meta)\n",
    "            loss   = loss_fn(logits, y)\n",
    "        scaler.scale(loss).backward()\n",
    "        scaler.unscale_(optimizer)\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "        if scheduler:\n",
    "            scheduler.step()\n",
    "        total_loss += loss.item()\n",
    "        all_labels.append(y.detach().cpu().numpy())\n",
    "        all_preds.append(torch.sigmoid(logits).detach().cpu().float().numpy())\n",
    "        if i % 300 == 0:\n",
    "            pbar.set_postfix({\n",
    "                \"loss\": f\"{total_loss/(i+1):.4f}\",\n",
    "                \"lr\":   f\"{optimizer.param_groups[-1]['lr']:.2e}\"\n",
    "            })\n",
    "    # ✅ safe AUC — skips PleuralThickening if single-class\n",
    "    auc, _ = safe_roc_auc(np.vstack(all_labels), np.vstack(all_preds))\n",
    "    return total_loss / len(loader), auc\n",
    "\n",
    "\n",
    "def val_epoch(model, loader, loss_fn):\n",
    "    model.eval()\n",
    "    total_loss, all_labels, all_preds = 0.0, [], []\n",
    "    with torch.no_grad():\n",
    "        for x, y, meta in tqdm(loader, desc=\"  Validate\", ncols=110):\n",
    "            x, y, meta = x.to(DEVICE), y.to(DEVICE), meta.to(DEVICE)\n",
    "            with torch.cuda.amp.autocast():\n",
    "                logits = model(x, meta)\n",
    "                loss   = loss_fn(logits, y)\n",
    "            total_loss += loss.item()\n",
    "            all_labels.append(y.cpu().numpy())\n",
    "            all_preds.append(torch.sigmoid(logits).cpu().float().numpy())\n",
    "    y_true = np.vstack(all_labels)\n",
    "    y_pred = np.vstack(all_preds)\n",
    "    # ✅ safe AUC\n",
    "    auc, per_class = safe_roc_auc(y_true, y_pred)\n",
    "    return total_loss / len(loader), auc, per_class\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def evaluate_model_with_meta(model, loader, label=\"Model\"):\n",
    "    model.eval()\n",
    "    all_labels, all_preds = [], []\n",
    "    for x, y, meta in tqdm(loader, desc=f\"  Eval {label}\", ncols=100):\n",
    "        x, meta = x.to(DEVICE), meta.to(DEVICE)\n",
    "        with torch.cuda.amp.autocast():\n",
    "            logits = model(x, meta)\n",
    "        all_labels.append(y.numpy())\n",
    "        all_preds.append(torch.sigmoid(logits).cpu().float().numpy())\n",
    "    y_true = np.vstack(all_labels)\n",
    "    y_pred = np.vstack(all_preds)\n",
    "    auc_macro, per_class = safe_roc_auc(y_true, y_pred)\n",
    "    print(f\"\\n{'='*55}\")\n",
    "    print(f\"  {label}  —  Test AUC (macro): {auc_macro:.4f}\")\n",
    "    print(f\"{'='*55}\")\n",
    "    for l, a in zip(LABELS, per_class):\n",
    "        if np.isnan(a):\n",
    "            print(f\"  {l:<22}  N/A  (single class in split)\")\n",
    "        else:\n",
    "            flag = \"  ⚠️ \" if a < 0.70 else (\"  ✅\" if a >= 0.85 else \"\")\n",
    "            print(f\"  {l:<22} {a:.4f}{flag}\")\n",
    "    return y_pred, y_true, auc_macro, per_class\n",
    "\n",
    "print(\"✅ All helpers defined correctly with safe AUC.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "ab4a457c-0c30-4135-bf3c-77e53b7f0cb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rebuilding DINOv2 Multi-Modal model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in C:\\Users\\91850/.cache\\torch\\hub\\facebookresearch_dinov2_main\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DINOv2 MultiModal         87.6M total | 29.4M trainable\n",
      "\n",
      "Starting DINOv2 training — max 15 epochs\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 01 Train: 100%|█████████████████████████| 7355/7355 [1:22:10<00:00,  1.49it/s, loss=0.0076, lr=7.42e-05]\n",
      "  Validate: 100%|█████████████████████████████████████████████████████████| 1298/1298 [11:50<00:00,  1.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1/15  |  Train Loss 0.0075  AUC 0.5762  |  Val Loss 0.0023  AUC 0.7262\n",
      "  Atelectasis            0.7051\n",
      "  Consolidation          0.7484\n",
      "  Infiltration           0.6039  ⚠️ \n",
      "  Pneumothorax           0.7712\n",
      "  Edema                  0.8693  ✅\n",
      "  Emphysema              0.8092\n",
      "  Fibrosis               0.6924  ⚠️ \n",
      "  Effusion               0.7489\n",
      "  Pneumonia              0.6281  ⚠️ \n",
      "  PleuralThickening       N/A\n",
      "  Cardiomegaly           0.7893\n",
      "  Nodule                 0.5702  ⚠️ \n",
      "  Mass                   0.6009  ⚠️ \n",
      "  Hernia                 0.9037  ✅\n",
      "  ✅ Best saved → D:\\Major Project\\best_ultimate_dinov2.pth  (Val AUC 0.7262)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 02 Train: 100%|█████████████████████████| 7355/7355 [1:05:00<00:00,  1.89it/s, loss=0.0038, lr=9.97e-05]\n",
      "  Validate: 100%|█████████████████████████████████████████████████████████| 1298/1298 [13:55<00:00,  1.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 2/15  |  Train Loss 0.0038  AUC 0.7213  |  Val Loss 0.0017  AUC 0.7701\n",
      "  Atelectasis            0.7440\n",
      "  Consolidation          0.7684\n",
      "  Infiltration           0.6209  ⚠️ \n",
      "  Pneumothorax           0.8360\n",
      "  Edema                  0.8886  ✅\n",
      "  Emphysema              0.8947  ✅\n",
      "  Fibrosis               0.7557\n",
      "  Effusion               0.8321\n",
      "  Pneumonia              0.6641  ⚠️ \n",
      "  PleuralThickening       N/A\n",
      "  Cardiomegaly           0.8295\n",
      "  Nodule                 0.5764  ⚠️ \n",
      "  Mass                   0.6612  ⚠️ \n",
      "  Hernia                 0.9404  ✅\n",
      "  ✅ Best saved → D:\\Major Project\\best_ultimate_dinov2.pth  (Val AUC 0.7701)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 03 Train: 100%|█████████████████████████| 7355/7355 [1:01:40<00:00,  1.99it/s, loss=0.0033, lr=9.71e-05]\n",
      "  Validate: 100%|█████████████████████████████████████████████████████████| 1298/1298 [13:13<00:00,  1.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 3/15  |  Train Loss 0.0033  AUC 0.7746  |  Val Loss 0.0019  AUC 0.7741\n",
      "  Atelectasis            0.7420\n",
      "  Consolidation          0.7631\n",
      "  Infiltration           0.6322  ⚠️ \n",
      "  Pneumothorax           0.8326\n",
      "  Edema                  0.8644  ✅\n",
      "  Emphysema              0.9051  ✅\n",
      "  Fibrosis               0.7538\n",
      "  Effusion               0.8437\n",
      "  Pneumonia              0.6857  ⚠️ \n",
      "  PleuralThickening       N/A\n",
      "  Cardiomegaly           0.8409\n",
      "  Nodule                 0.6387  ⚠️ \n",
      "  Mass                   0.7357\n",
      "  Hernia                 0.8257\n",
      "  ✅ Best saved → D:\\Major Project\\best_ultimate_dinov2.pth  (Val AUC 0.7741)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 04 Train: 100%|███████████████████████████| 7355/7355 [56:54<00:00,  2.15it/s, loss=0.0029, lr=9.19e-05]\n",
      "  Validate: 100%|█████████████████████████████████████████████████████████| 1298/1298 [14:03<00:00,  1.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 4/15  |  Train Loss 0.0029  AUC 0.8118  |  Val Loss 0.0018  AUC 0.7776\n",
      "  Atelectasis            0.7566\n",
      "  Consolidation          0.7732\n",
      "  Infiltration           0.6254  ⚠️ \n",
      "  Pneumothorax           0.8335\n",
      "  Edema                  0.8760  ✅\n",
      "  Emphysema              0.9095  ✅\n",
      "  Fibrosis               0.7186\n",
      "  Effusion               0.8498\n",
      "  Pneumonia              0.6758  ⚠️ \n",
      "  PleuralThickening       N/A\n",
      "  Cardiomegaly           0.8488\n",
      "  Nodule                 0.6161  ⚠️ \n",
      "  Mass                   0.7588\n",
      "  Hernia                 0.8664  ✅\n",
      "  ✅ Best saved → D:\\Major Project\\best_ultimate_dinov2.pth  (Val AUC 0.7776)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 05 Train: 100%|█████████████████████████| 7355/7355 [1:03:30<00:00,  1.93it/s, loss=0.0025, lr=8.45e-05]\n",
      "  Validate: 100%|█████████████████████████████████████████████████████████| 1298/1298 [12:41<00:00,  1.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 5/15  |  Train Loss 0.0025  AUC 0.8389  |  Val Loss 0.0017  AUC 0.7835\n",
      "  Atelectasis            0.7536\n",
      "  Consolidation          0.7868\n",
      "  Infiltration           0.6294  ⚠️ \n",
      "  Pneumothorax           0.8388\n",
      "  Edema                  0.8532  ✅\n",
      "  Emphysema              0.9153  ✅\n",
      "  Fibrosis               0.7459\n",
      "  Effusion               0.8504  ✅\n",
      "  Pneumonia              0.6637  ⚠️ \n",
      "  PleuralThickening       N/A\n",
      "  Cardiomegaly           0.8583  ✅\n",
      "  Nodule                 0.6398  ⚠️ \n",
      "  Mass                   0.7583\n",
      "  Hernia                 0.8912  ✅\n",
      "  ✅ Best saved → D:\\Major Project\\best_ultimate_dinov2.pth  (Val AUC 0.7835)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 06 Train: 100%|███████████████████████████| 7355/7355 [57:04<00:00,  2.15it/s, loss=0.0022, lr=7.52e-05]\n",
      "  Validate: 100%|█████████████████████████████████████████████████████████| 1298/1298 [13:00<00:00,  1.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 6/15  |  Train Loss 0.0022  AUC 0.8592  |  Val Loss 0.0020  AUC 0.7763\n",
      "  Atelectasis            0.7553\n",
      "  Consolidation          0.7705\n",
      "  Infiltration           0.6223  ⚠️ \n",
      "  Pneumothorax           0.8422\n",
      "  Edema                  0.8486\n",
      "  Emphysema              0.9043  ✅\n",
      "  Fibrosis               0.7382\n",
      "  Effusion               0.8547  ✅\n",
      "  Pneumonia              0.6371  ⚠️ \n",
      "  PleuralThickening       N/A\n",
      "  Cardiomegaly           0.8510  ✅\n",
      "  Nodule                 0.6574  ⚠️ \n",
      "  Mass                   0.7892\n",
      "  Hernia                 0.8208\n",
      "  No improvement (1/5)  [best so far: 0.7835]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 07 Train: 100%|███████████████████████████| 7355/7355 [57:28<00:00,  2.13it/s, loss=0.0019, lr=6.46e-05]\n",
      "  Validate: 100%|█████████████████████████████████████████████████████████| 1298/1298 [13:17<00:00,  1.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 7/15  |  Train Loss 0.0019  AUC 0.8717  |  Val Loss 0.0021  AUC 0.7762\n",
      "  Atelectasis            0.7584\n",
      "  Consolidation          0.7665\n",
      "  Infiltration           0.6300  ⚠️ \n",
      "  Pneumothorax           0.8293\n",
      "  Edema                  0.8650  ✅\n",
      "  Emphysema              0.9014  ✅\n",
      "  Fibrosis               0.7174\n",
      "  Effusion               0.8547  ✅\n",
      "  Pneumonia              0.6431  ⚠️ \n",
      "  PleuralThickening       N/A\n",
      "  Cardiomegaly           0.8615  ✅\n",
      "  Nodule                 0.6339  ⚠️ \n",
      "  Mass                   0.7709\n",
      "  Hernia                 0.8579  ✅\n",
      "  No improvement (2/5)  [best so far: 0.7835]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 08 Train: 100%|█████████████████████████| 7355/7355 [1:06:59<00:00,  1.83it/s, loss=0.0018, lr=5.32e-05]\n",
      "  Validate: 100%|█████████████████████████████████████████████████████████| 1298/1298 [14:48<00:00,  1.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 8/15  |  Train Loss 0.0018  AUC 0.8826  |  Val Loss 0.0021  AUC 0.7703\n",
      "  Atelectasis            0.7620\n",
      "  Consolidation          0.7590\n",
      "  Infiltration           0.6368  ⚠️ \n",
      "  Pneumothorax           0.8452\n",
      "  Edema                  0.8292\n",
      "  Emphysema              0.8942  ✅\n",
      "  Fibrosis               0.7317\n",
      "  Effusion               0.8611  ✅\n",
      "  Pneumonia              0.6671  ⚠️ \n",
      "  PleuralThickening       N/A\n",
      "  Cardiomegaly           0.8471\n",
      "  Nodule                 0.6486  ⚠️ \n",
      "  Mass                   0.7850\n",
      "  Hernia                 0.7469\n",
      "  No improvement (3/5)  [best so far: 0.7835]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 09 Train: 100%|█████████████████████████| 7355/7355 [1:03:31<00:00,  1.93it/s, loss=0.0016, lr=4.16e-05]\n",
      "  Validate: 100%|█████████████████████████████████████████████████████████| 1298/1298 [13:15<00:00,  1.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 9/15  |  Train Loss 0.0016  AUC 0.8905  |  Val Loss 0.0023  AUC 0.7721\n",
      "  Atelectasis            0.7712\n",
      "  Consolidation          0.7717\n",
      "  Infiltration           0.6248  ⚠️ \n",
      "  Pneumothorax           0.8505  ✅\n",
      "  Edema                  0.8151\n",
      "  Emphysema              0.9007  ✅\n",
      "  Fibrosis               0.7472\n",
      "  Effusion               0.8661  ✅\n",
      "  Pneumonia              0.6321  ⚠️ \n",
      "  PleuralThickening       N/A\n",
      "  Cardiomegaly           0.8491\n",
      "  Nodule                 0.6523  ⚠️ \n",
      "  Mass                   0.7729\n",
      "  Hernia                 0.7828\n",
      "  No improvement (4/5)  [best so far: 0.7835]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10 Train: 100%|█████████████████████████| 7355/7355 [1:02:16<00:00,  1.97it/s, loss=0.0015, lr=3.04e-05]\n",
      "  Validate: 100%|█████████████████████████████████████████████████████████| 1298/1298 [13:25<00:00,  1.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 10/15  |  Train Loss 0.0015  AUC 0.8972  |  Val Loss 0.0024  AUC 0.7717\n",
      "  Atelectasis            0.7692\n",
      "  Consolidation          0.7604\n",
      "  Infiltration           0.6247  ⚠️ \n",
      "  Pneumothorax           0.8493\n",
      "  Edema                  0.8375\n",
      "  Emphysema              0.8988  ✅\n",
      "  Fibrosis               0.7341\n",
      "  Effusion               0.8626  ✅\n",
      "  Pneumonia              0.6284  ⚠️ \n",
      "  PleuralThickening       N/A\n",
      "  Cardiomegaly           0.8523  ✅\n",
      "  Nodule                 0.6535  ⚠️ \n",
      "  Mass                   0.7681\n",
      "  Hernia                 0.7938\n",
      "  No improvement (5/5)  [best so far: 0.7835]\n",
      "  🛑 Early stopping triggered.\n",
      "\n",
      "✅ DINOv2 training complete.  Best Val AUC: 0.7835\n"
     ]
    }
   ],
   "source": [
    "# CELL 12 FIXED: Rebuild DINOv2 and retrain with correct AUC + saving logic\n",
    "\n",
    "# Rebuild model fresh (previous run never saved a valid checkpoint)\n",
    "print(\"Rebuilding DINOv2 Multi-Modal model...\")\n",
    "model_dino = DINOv2MultiModal(freeze_blocks=8).to(DEVICE)\n",
    "count_params(model_dino, \"DINOv2 MultiModal\")\n",
    "\n",
    "loss_fn = FocalLossWithSmoothing(CLASS_WEIGHTS, gamma=2.0, smoothing=LABEL_SMOOTH)\n",
    "\n",
    "# Layer-wise LR\n",
    "backbone_params, head_params = [], []\n",
    "for name, param in model_dino.named_parameters():\n",
    "    if not param.requires_grad:\n",
    "        continue\n",
    "    if any(k in name for k in [\"backbone\", \"blocks\", \"norm\", \"patch_embed\"]):\n",
    "        backbone_params.append(param)\n",
    "    else:\n",
    "        head_params.append(param)\n",
    "\n",
    "optimizer_dino = torch.optim.AdamW([\n",
    "    {\"params\": backbone_params, \"lr\": 5e-6},\n",
    "    {\"params\": head_params,     \"lr\": 1e-4},\n",
    "], weight_decay=1e-4)\n",
    "\n",
    "NUM_EPOCHS_DINO = 15\n",
    "PATIENCE_DINO   = 5\n",
    "total_steps     = NUM_EPOCHS_DINO * len(TRAIN_DL)\n",
    "\n",
    "scheduler_dino = OneCycleLR(\n",
    "    optimizer_dino,\n",
    "    max_lr           = [5e-6, 1e-4],\n",
    "    total_steps      = total_steps,\n",
    "    pct_start        = 0.1,\n",
    "    anneal_strategy  = \"cos\",\n",
    "    div_factor       = 25.0,\n",
    "    final_div_factor = 1000.0,\n",
    ")\n",
    "\n",
    "scaler_dino  = torch.cuda.amp.GradScaler()\n",
    "best_auc_d   = -1.0     # ✅ start at -1 so first valid epoch always saves\n",
    "patience_ctr = 0\n",
    "dino_history = []\n",
    "\n",
    "print(f\"\\nStarting DINOv2 training — max {NUM_EPOCHS_DINO} epochs\\n\")\n",
    "\n",
    "for epoch in range(1, NUM_EPOCHS_DINO + 1):\n",
    "    tr_loss, tr_auc           = train_epoch(model_dino, TRAIN_DL, loss_fn,\n",
    "                                             optimizer_dino, scaler_dino,\n",
    "                                             scheduler_dino, epoch)\n",
    "    val_loss, val_auc, val_pc = val_epoch(model_dino, VAL_DL, loss_fn)\n",
    "\n",
    "    # ✅ Guard against nan before comparison\n",
    "    val_auc_safe = val_auc if not np.isnan(val_auc) else 0.0\n",
    "    tr_auc_safe  = tr_auc  if not np.isnan(tr_auc)  else 0.0\n",
    "\n",
    "    print(f\"\\nEpoch {epoch}/{NUM_EPOCHS_DINO}  |  \"\n",
    "          f\"Train Loss {tr_loss:.4f}  AUC {tr_auc_safe:.4f}  |  \"\n",
    "          f\"Val Loss {val_loss:.4f}  AUC {val_auc_safe:.4f}\")\n",
    "\n",
    "    for l, a in zip(LABELS, val_pc):\n",
    "        if np.isnan(a):\n",
    "            print(f\"  {l:<22}  N/A\")\n",
    "        else:\n",
    "            flag = \"  ⚠️ \" if a < 0.70 else (\"  ✅\" if a >= 0.85 else \"\")\n",
    "            print(f\"  {l:<22} {a:.4f}{flag}\")\n",
    "\n",
    "    dino_history.append({\n",
    "        \"epoch\":         epoch,\n",
    "        \"train_loss\":    tr_loss,\n",
    "        \"train_auc\":     tr_auc_safe,\n",
    "        \"val_loss\":      val_loss,\n",
    "        \"val_auc\":       val_auc_safe,\n",
    "        \"per_class_auc\": [float(a) if not np.isnan(a) else None\n",
    "                          for a in val_pc],\n",
    "    })\n",
    "\n",
    "    # ✅ Safe comparison: only update if val_auc is a real number\n",
    "    if not np.isnan(val_auc) and val_auc_safe > best_auc_d:\n",
    "        best_auc_d   = val_auc_safe\n",
    "        patience_ctr = 0\n",
    "        torch.save(model_dino.state_dict(), PATH_DINO)\n",
    "        print(f\"  ✅ Best saved → {PATH_DINO}  (Val AUC {best_auc_d:.4f})\")\n",
    "    else:\n",
    "        patience_ctr += 1\n",
    "        print(f\"  No improvement ({patience_ctr}/{PATIENCE_DINO})  \"\n",
    "              f\"[best so far: {best_auc_d:.4f}]\")\n",
    "        if patience_ctr >= PATIENCE_DINO:\n",
    "            print(\"  🛑 Early stopping triggered.\")\n",
    "            break\n",
    "\n",
    "with open(os.path.join(BASE_DIR, \"phase7_dinov2_results.json\"), \"w\") as f:\n",
    "    json.dump(dino_history, f, indent=2)\n",
    "\n",
    "print(f\"\\n✅ DINOv2 training complete.  Best Val AUC: {best_auc_d:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "b39d1454-10dc-4eda-be81-e2d225582a62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading best DINOv2 weights from:\n",
      "  D:\\Major Project\\best_ultimate_dinov2.pth\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  Eval DINOv2 MultiModal: 100%|█████████████████████████████████| 2560/2560 [26:53<00:00,  1.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=======================================================\n",
      "  DINOv2 MultiModal  —  Test AUC (macro): 0.7624\n",
      "=======================================================\n",
      "  Atelectasis            0.7141\n",
      "  Consolidation          0.7171\n",
      "  Infiltration           0.6746  ⚠️ \n",
      "  Pneumothorax           0.8505  ✅\n",
      "  Edema                  0.8090\n",
      "  Emphysema              0.9107  ✅\n",
      "  Fibrosis               0.7476\n",
      "  Effusion               0.7752\n",
      "  Pneumonia              0.6160  ⚠️ \n",
      "  PleuralThickening       N/A  (single class in split)\n",
      "  Cardiomegaly           0.8372\n",
      "  Nodule                 0.6609  ⚠️ \n",
      "  Mass                   0.7291\n",
      "  Hernia                 0.8697  ✅\n",
      "\n",
      "  Minority Avg AUC : 0.7906\n",
      "  Hernia                 0.8697\n",
      "  Pneumonia              0.6160\n",
      "  Edema                  0.8090\n",
      "  Emphysema              0.9107\n",
      "  Fibrosis               0.7476\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# CELL 13: Load best DINOv2 checkpoint and evaluate on test set\n",
    "\n",
    "print(f\"Loading best DINOv2 weights from:\\n  {PATH_DINO}\\n\")\n",
    "model_dino.load_state_dict(torch.load(PATH_DINO, map_location=DEVICE))\n",
    "\n",
    "dino_preds, _, dino_auc, dino_pc = evaluate_model_with_meta(\n",
    "    model_dino, TEST_DL, \"DINOv2 MultiModal\"\n",
    ")\n",
    "\n",
    "m_aucs_dino = [dino_pc[LABELS.index(c)] for c in minority_classes]\n",
    "print(f\"\\n  Minority Avg AUC : {np.mean(m_aucs_dino):.4f}\")\n",
    "for c, a in zip(minority_classes, m_aucs_dino):\n",
    "    print(f\"  {c:<22} {a:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5d98d5c0-d35d-42c3-8e86-2da963961ce6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in C:\\Users\\91850/.cache\\torch\\hub\\facebookresearch_dinov2_main\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DINOv2 MultiModal         87.6M total | 29.4M trainable\n",
      "✅ DINOv2 loaded.\n"
     ]
    }
   ],
   "source": [
    "# Load DINOv2 best checkpoint\n",
    "\n",
    "model_dino = DINOv2MultiModal(freeze_blocks=8).to(DEVICE)\n",
    "model_dino.load_state_dict(torch.load(PATH_DINO, map_location=DEVICE))\n",
    "model_dino.eval()\n",
    "count_params(model_dino, \"DINOv2 MultiModal\")\n",
    "\n",
    "print(\"✅ DINOv2 loaded.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7c80ee9e-d3e7-4535-b731-347019f11bc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✅ DEVICE / LABELS / BASE_DIR\n",
      "  ✅ TEST_DL\n",
      "  ✅ model_b0\n",
      "  ✅ model_b3\n",
      "  ✅ model_vit\n",
      "  ✅ model_dino\n",
      "  ✅ safe_roc_auc\n",
      "\n",
      "✅ All ready — run Resume Cell\n"
     ]
    }
   ],
   "source": [
    "# QUICK VERIFY CELL — run this first to see what's missing\n",
    "checks = {\n",
    "    \"DEVICE / LABELS / BASE_DIR\":     lambda: bool(DEVICE and LABELS and BASE_DIR),\n",
    "    \"TEST_DL\":                         lambda: TEST_DL is not None,\n",
    "    \"model_b0\":                        lambda: model_b0 is not None,\n",
    "    \"model_b3\":                        lambda: model_b3 is not None,\n",
    "    \"model_vit\":                       lambda: model_vit is not None,\n",
    "    \"model_dino\":                      lambda: model_dino is not None,\n",
    "    \"safe_roc_auc\":                    lambda: callable(safe_roc_auc),\n",
    "}\n",
    "\n",
    "all_ok = True\n",
    "for name, check in checks.items():\n",
    "    try:\n",
    "        ok = check()\n",
    "        print(f\"  {'✅' if ok else '❌'} {name}\")\n",
    "        if not ok:\n",
    "            all_ok = False\n",
    "    except NameError:\n",
    "        print(f\"  ❌ {name}  ← NOT DEFINED\")\n",
    "        all_ok = False\n",
    "\n",
    "print(f\"\\n{'✅ All ready — run Resume Cell' if all_ok else '❌ Fix missing items above first'}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7dc7c7e1-b13b-440b-b06c-69ea775b1f34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking for cached predictions...\n",
      "\n",
      "  ✅ Loaded from cache : cache_test_labels.npy\n",
      "  🔄 Computing         : EfficientNet-B0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████| 2560/2560 [28:59<00:00,  1.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  💾 Saved to cache    : cache_b0_preds.npy\n",
      "  🔄 Computing         : EfficientNet-B3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████| 2560/2560 [31:10<00:00,  1.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  💾 Saved to cache    : cache_b3_preds.npy\n",
      "  🔄 Computing         : ViT-Base/16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████| 2560/2560 [30:48<00:00,  1.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  💾 Saved to cache    : cache_vit_preds.npy\n",
      "  🔄 Computing         : DINOv2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████| 2560/2560 [33:07<00:00,  1.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  💾 Saved to cache    : cache_dino_preds.npy\n",
      "\n",
      "=======================================================\n",
      "  Model                             AUC\n",
      "  ----------------------------------------\n",
      "  EfficientNet-B0                0.8293\n",
      "  EfficientNet-B3                0.8350\n",
      "  ViT-Base/16                    0.8379\n",
      "  DINOv2 MultiModal              0.7624\n",
      "=======================================================\n",
      "\n",
      "✅ All predictions ready — continue from Cell 14.\n"
     ]
    }
   ],
   "source": [
    "# RESUME CELL: Regenerate all predictions after reopening notebook\n",
    "# Run AFTER cells 1,2,3,4,5,7,8,11 have been re-executed\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "RESUME_CACHE_DIR = BASE_DIR   # predictions saved here as .npy files\n",
    "print(\"Checking for cached predictions...\\n\")\n",
    "\n",
    "# ── Helper: try to load from cache, else recompute ──────────────────────────\n",
    "def load_or_compute(cache_path, compute_fn, label):\n",
    "    if os.path.exists(cache_path):\n",
    "        arr = np.load(cache_path)\n",
    "        print(f\"  ✅ Loaded from cache : {os.path.basename(cache_path)}\")\n",
    "        return arr\n",
    "    else:\n",
    "        print(f\"  🔄 Computing         : {label}\")\n",
    "        arr = compute_fn()\n",
    "        np.save(cache_path, arr)\n",
    "        print(f\"  💾 Saved to cache    : {os.path.basename(cache_path)}\")\n",
    "        return arr\n",
    "\n",
    "\n",
    "# ── Predict functions ────────────────────────────────────────────────────────\n",
    "@torch.no_grad()\n",
    "def get_test_preds_no_meta(model):\n",
    "    model.eval()\n",
    "    preds = []\n",
    "    for x, y, meta in tqdm(TEST_DL, ncols=100):\n",
    "        x = x.to(DEVICE)\n",
    "        with torch.cuda.amp.autocast():\n",
    "            logits = model(x, None)\n",
    "        preds.append(torch.sigmoid(logits).cpu().float().numpy())\n",
    "    return np.vstack(preds)\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def get_test_preds_with_meta(model):\n",
    "    model.eval()\n",
    "    preds = []\n",
    "    for x, y, meta in tqdm(TEST_DL, ncols=100):\n",
    "        x, meta = x.to(DEVICE), meta.to(DEVICE)\n",
    "        with torch.cuda.amp.autocast():\n",
    "            logits = model(x, meta)\n",
    "        preds.append(torch.sigmoid(logits).cpu().float().numpy())\n",
    "    return np.vstack(preds)\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def get_test_labels():\n",
    "    labels = []\n",
    "    for x, y, meta in tqdm(TEST_DL, desc=\"Labels\", ncols=100):\n",
    "        labels.append(y.numpy())\n",
    "    return np.vstack(labels)\n",
    "\n",
    "\n",
    "# ── Load or compute all predictions ─────────────────────────────────────────\n",
    "test_labels = load_or_compute(\n",
    "    os.path.join(RESUME_CACHE_DIR, \"cache_test_labels.npy\"),\n",
    "    get_test_labels, \"test labels\"\n",
    ")\n",
    "\n",
    "b0_preds = load_or_compute(\n",
    "    os.path.join(RESUME_CACHE_DIR, \"cache_b0_preds.npy\"),\n",
    "    lambda: get_test_preds_no_meta(model_b0), \"EfficientNet-B0\"\n",
    ")\n",
    "\n",
    "b3_preds = load_or_compute(\n",
    "    os.path.join(RESUME_CACHE_DIR, \"cache_b3_preds.npy\"),\n",
    "    lambda: get_test_preds_no_meta(model_b3), \"EfficientNet-B3\"\n",
    ")\n",
    "\n",
    "vit_preds = load_or_compute(\n",
    "    os.path.join(RESUME_CACHE_DIR, \"cache_vit_preds.npy\"),\n",
    "    lambda: get_test_preds_no_meta(model_vit), \"ViT-Base/16\"\n",
    ")\n",
    "\n",
    "dino_preds = load_or_compute(\n",
    "    os.path.join(RESUME_CACHE_DIR, \"cache_dino_preds.npy\"),\n",
    "    lambda: get_test_preds_with_meta(model_dino), \"DINOv2\"\n",
    ")\n",
    "\n",
    "\n",
    "# ── Recompute per-model AUCs ─────────────────────────────────────────────────\n",
    "b0_auc,   b0_pc   = safe_roc_auc(test_labels, b0_preds)\n",
    "b3_auc,   b3_pc   = safe_roc_auc(test_labels, b3_preds)\n",
    "vit_auc,  vit_pc  = safe_roc_auc(test_labels, vit_preds)\n",
    "dino_auc, dino_pc = safe_roc_auc(test_labels, dino_preds)\n",
    "\n",
    "minority_classes = [\"Hernia\",\"Pneumonia\",\"Edema\",\"Emphysema\",\"Fibrosis\"]\n",
    "\n",
    "print(f\"\\n{'='*55}\")\n",
    "print(f\"  {'Model':<28} {'AUC':>8}\")\n",
    "print(f\"  {'-'*40}\")\n",
    "print(f\"  {'EfficientNet-B0':<28} {b0_auc:>8.4f}\")\n",
    "print(f\"  {'EfficientNet-B3':<28} {b3_auc:>8.4f}\")\n",
    "print(f\"  {'ViT-Base/16':<28} {vit_auc:>8.4f}\")\n",
    "print(f\"  {'DINOv2 MultiModal':<28} {dino_auc:>8.4f}\")\n",
    "print(f\"{'='*55}\")\n",
    "print(\"\\n✅ All predictions ready — continue from Cell 14.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3ea06d96-f20a-476f-bfab-a02444d82f0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing 4-way ensemble weights...\n",
      "\n",
      "  B0=0.25  B3=0.15  ViT=0.25  DINO=0.35  →  AUC=0.8576  ← BEST\n",
      "  B0=0.30  B3=0.10  ViT=0.25  DINO=0.35  →  AUC=0.8566\n",
      "  B0=0.20  B3=0.15  ViT=0.30  DINO=0.35  →  AUC=0.8580  ← BEST\n",
      "  B0=0.25  B3=0.15  ViT=0.30  DINO=0.30  →  AUC=0.8592  ← BEST\n",
      "  B0=0.25  B3=0.20  ViT=0.20  DINO=0.35  →  AUC=0.8574\n",
      "  B0=0.20  B3=0.10  ViT=0.30  DINO=0.40  →  AUC=0.8554\n",
      "  B0=0.30  B3=0.15  ViT=0.20  DINO=0.35  →  AUC=0.8567\n",
      "  B0=0.20  B3=0.10  ViT=0.25  DINO=0.45  →  AUC=0.8528\n",
      "\n",
      "=======================================================\n",
      "  Best 4-Way Ensemble AUC : 0.8592\n",
      "  Weights → B0=0.25  B3=0.15  ViT=0.3  DINO=0.3\n",
      "=======================================================\n",
      "\n",
      "Per-class AUC (4-Way Ensemble):\n",
      "  Atelectasis            0.7533\n",
      "  Consolidation          0.7703\n",
      "  Infiltration           0.7189\n",
      "  Pneumothorax           0.9002  ✅\n",
      "  Edema                  0.9231  ✅\n",
      "  Emphysema              0.9570  ✅\n",
      "  Fibrosis               0.9424  ✅\n",
      "  Effusion               0.8159\n",
      "  Pneumonia              0.8963  ✅\n",
      "  PleuralThickening       N/A\n",
      "  Cardiomegaly           0.9323  ✅\n",
      "  Nodule                 0.7531\n",
      "  Mass                   0.8187\n",
      "  Hernia                 0.9885  ✅\n",
      "\n",
      "  Minority Avg AUC : 0.9415\n",
      "  Hernia                 0.9885\n",
      "  Pneumonia              0.8963\n",
      "  Edema                  0.9231\n",
      "  Emphysema              0.9570\n",
      "  Fibrosis               0.9424\n"
     ]
    }
   ],
   "source": [
    "# CELL 14 FIXED: 4-Way Ensemble using safe_roc_auc (already defined in Cell 11)\n",
    "\n",
    "weight_configs_4 = [\n",
    "    (0.25, 0.15, 0.25, 0.35),\n",
    "    (0.30, 0.10, 0.25, 0.35),\n",
    "    (0.20, 0.15, 0.30, 0.35),\n",
    "    (0.25, 0.15, 0.30, 0.30),\n",
    "    (0.25, 0.20, 0.20, 0.35),\n",
    "    (0.20, 0.10, 0.30, 0.40),\n",
    "    (0.30, 0.15, 0.20, 0.35),\n",
    "    (0.20, 0.10, 0.25, 0.45),\n",
    "]\n",
    "\n",
    "best4_auc, best4_w, best4_preds = -1.0, None, None\n",
    "print(\"Testing 4-way ensemble weights...\\n\")\n",
    "\n",
    "for wb0, wb3, wvit, wdino in weight_configs_4:\n",
    "    ens       = wb0*b0_preds + wb3*b3_preds + wvit*vit_preds + wdino*dino_preds\n",
    "    auc, _    = safe_roc_auc(test_labels, ens)           # ✅ use safe_roc_auc\n",
    "    auc_safe  = auc if not np.isnan(auc) else 0.0        # ✅ guard nan\n",
    "    flag      = \"  ← BEST\" if auc_safe > best4_auc else \"\"\n",
    "    print(f\"  B0={wb0:.2f}  B3={wb3:.2f}  ViT={wvit:.2f}  \"\n",
    "          f\"DINO={wdino:.2f}  →  AUC={auc_safe:.4f}{flag}\")\n",
    "    if auc_safe > best4_auc:\n",
    "        best4_auc   = auc_safe\n",
    "        best4_w     = (wb0, wb3, wvit, wdino)\n",
    "        best4_preds = ens.copy()                         # ✅ always set together\n",
    "\n",
    "# Final safety check\n",
    "if best4_preds is None:\n",
    "    print(\"\\n⚠️  All configs returned nan — using equal weights as fallback\")\n",
    "    best4_w     = (0.25, 0.25, 0.25, 0.25)\n",
    "    best4_preds = 0.25*b0_preds + 0.25*b3_preds + 0.25*vit_preds + 0.25*dino_preds\n",
    "    best4_auc, _ = safe_roc_auc(test_labels, best4_preds)\n",
    "\n",
    "_, best4_pc  = safe_roc_auc(test_labels, best4_preds)\n",
    "m_aucs_4     = [best4_pc[LABELS.index(c)] for c in minority_classes]\n",
    "\n",
    "print(f\"\\n{'='*55}\")\n",
    "print(f\"  Best 4-Way Ensemble AUC : {best4_auc:.4f}\")\n",
    "print(f\"  Weights → B0={best4_w[0]}  B3={best4_w[1]}  \"\n",
    "      f\"ViT={best4_w[2]}  DINO={best4_w[3]}\")\n",
    "print(f\"{'='*55}\")\n",
    "\n",
    "print(\"\\nPer-class AUC (4-Way Ensemble):\")\n",
    "for l, a in zip(LABELS, best4_pc):\n",
    "    if np.isnan(a):\n",
    "        print(f\"  {l:<22}  N/A\")\n",
    "    else:\n",
    "        flag = \"  ⚠️ \" if a < 0.70 else (\"  ✅\" if a >= 0.85 else \"\")\n",
    "        print(f\"  {l:<22} {a:.4f}{flag}\")\n",
    "\n",
    "print(f\"\\n  Minority Avg AUC : {np.nanmean(m_aucs_4):.4f}\")\n",
    "for c, a in zip(minority_classes, m_aucs_4):\n",
    "    val_str = f\"{a:.4f}\" if not np.isnan(a) else \"N/A\"\n",
    "    print(f\"  {c:<22} {val_str}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "58ce2f0d-4f0d-423c-9e3b-e78733999d45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "====================================================================\n",
      "  Model                                 AUC    Minority Avg\n",
      "  ---------------------------------------------------------------\n",
      "  EfficientNet-B0                    0.8293\n",
      "  EfficientNet-B3                    0.8350\n",
      "  ViT-Base/16                        0.8379\n",
      "  DINOv2 MultiModal                  0.7624\n",
      "  ---------------------------------------------------------------\n",
      "  3-Way Ensemble (B0+B3+ViT)         0.8577          0.9451\n",
      "  4-Way Ensemble (All)               0.8592          0.9415\n",
      "====================================================================\n",
      "\n",
      "                      Per-Class AUC Comparison                      \n",
      "  Disease                     B0      B3     ViT  DINOv2   3-Way   4-Way\n",
      "  ---------------------------------------------------------------\n",
      "  Atelectasis             0.7106  0.7096  0.7324  0.7141  0.7427  0.7533\n",
      "  Consolidation           0.7463  0.7448  0.7590  0.7171  0.7735  0.7703\n",
      "  Infiltration            0.7004  0.6867  0.6749  0.6746  0.7080  0.7189\n",
      "  Pneumothorax            0.8752  0.8780  0.8852  0.8505  0.8993  0.9002\n",
      "  Edema                   0.8988  0.9207  0.9067  0.8090  0.9343  0.9231\n",
      "  Emphysema               0.9347  0.9474  0.9386  0.9107  0.9599  0.9570\n",
      "  Fibrosis                0.9107  0.9365  0.9113  0.7476  0.9463  0.9424\n",
      "  Effusion                0.7849  0.7766  0.7945  0.7752  0.8111  0.8159\n",
      "  Pneumonia               0.8687  0.8834  0.8666  0.6160  0.9021  0.8963\n",
      "  PleuralThickening          N/A     N/A     N/A     N/A     N/A     N/A\n",
      "  Cardiomegaly            0.9142  0.9192  0.9239  0.8372  0.9445  0.9323\n",
      "  Nodule                  0.6995  0.7100  0.7245  0.6609  0.7382  0.7531\n",
      "  Mass                    0.7583  0.7579  0.7988  0.7291  0.8074  0.8187\n",
      "  Hernia                  0.9783  0.9843  0.9757  0.8697  0.9831  0.9885\n",
      "\n",
      "✅ Results saved → D:\\Major Project\\FINAL_4WAY_ENSEMBLE_RESULTS.json\n"
     ]
    }
   ],
   "source": [
    "# CELL 15 FIXED: Summary table with nanmean for minority averages\n",
    "\n",
    "print(f\"\\n{'='*68}\")\n",
    "print(f\"  {'Model':<32} {'AUC':>8}  {'Minority Avg':>14}\")\n",
    "print(f\"  {'-'*63}\")\n",
    "print(f\"  {'EfficientNet-B0':<32} {b0_auc:>8.4f}\")\n",
    "print(f\"  {'EfficientNet-B3':<32} {b3_auc:>8.4f}\")\n",
    "print(f\"  {'ViT-Base/16':<32} {vit_auc:>8.4f}\")\n",
    "print(f\"  {'DINOv2 MultiModal':<32} {dino_auc:>8.4f}\")\n",
    "print(f\"  {'-'*63}\")\n",
    "print(f\"  {'3-Way Ensemble (B0+B3+ViT)':<32} {best3_auc:>8.4f}\"\n",
    "      f\"  {np.nanmean(m_aucs_3):>14.4f}\")\n",
    "print(f\"  {'4-Way Ensemble (All)':<32} {best4_auc:>8.4f}\"\n",
    "      f\"  {np.nanmean(m_aucs_4):>14.4f}\")\n",
    "print(f\"{'='*68}\")\n",
    "\n",
    "# Per-class comparison\n",
    "print(f\"\\n{'Per-Class AUC Comparison':^68}\")\n",
    "print(f\"  {'Disease':<22} {'B0':>7} {'B3':>7} {'ViT':>7} \"\n",
    "      f\"{'DINOv2':>7} {'3-Way':>7} {'4-Way':>7}\")\n",
    "print(f\"  {'-'*63}\")\n",
    "for i, l in enumerate(LABELS):\n",
    "    def fmt(v):\n",
    "        return f\"{v:>7.4f}\" if not np.isnan(v) else \"    N/A\"\n",
    "    print(f\"  {l:<22}\"\n",
    "          f\" {fmt(b0_pc[i])}\"\n",
    "          f\" {fmt(b3_pc[i])}\"\n",
    "          f\" {fmt(vit_pc[i])}\"\n",
    "          f\" {fmt(dino_pc[i])}\"\n",
    "          f\" {fmt(best3_pc[i])}\"\n",
    "          f\" {fmt(best4_pc[i])}\")\n",
    "\n",
    "# Save results JSON\n",
    "final_results = {\n",
    "    \"individual_models\": {\n",
    "        \"EfficientNet-B0\":   {\n",
    "            \"test_auc_macro\": b0_auc,\n",
    "            \"per_class\": {l: (float(a) if not np.isnan(a) else None)\n",
    "                          for l, a in zip(LABELS, b0_pc)}\n",
    "        },\n",
    "        \"EfficientNet-B3\":   {\n",
    "            \"test_auc_macro\": b3_auc,\n",
    "            \"per_class\": {l: (float(a) if not np.isnan(a) else None)\n",
    "                          for l, a in zip(LABELS, b3_pc)}\n",
    "        },\n",
    "        \"ViT-Base16\":        {\n",
    "            \"test_auc_macro\": vit_auc,\n",
    "            \"per_class\": {l: (float(a) if not np.isnan(a) else None)\n",
    "                          for l, a in zip(LABELS, vit_pc)}\n",
    "        },\n",
    "        \"DINOv2-MultiModal\": {\n",
    "            \"test_auc_macro\": dino_auc,\n",
    "            \"per_class\": {l: (float(a) if not np.isnan(a) else None)\n",
    "                          for l, a in zip(LABELS, dino_pc)}\n",
    "        },\n",
    "    },\n",
    "    \"ensemble_3way\": {\n",
    "        \"weights\":        dict(zip([\"B0\",\"B3\",\"ViT\"], best3_w)),\n",
    "        \"test_auc_macro\": best3_auc,\n",
    "        \"per_class_auc\":  {l: (float(a) if not np.isnan(a) else None)\n",
    "                           for l, a in zip(LABELS, best3_pc)},\n",
    "        \"minority_avg\":   float(np.nanmean(m_aucs_3)),\n",
    "        \"minority_detail\":{ c: (float(a) if not np.isnan(a) else None)\n",
    "                            for c, a in zip(minority_classes, m_aucs_3)},\n",
    "    },\n",
    "    \"ensemble_4way\": {\n",
    "        \"weights\":        dict(zip([\"B0\",\"B3\",\"ViT\",\"DINOv2\"], best4_w)),\n",
    "        \"test_auc_macro\": best4_auc,\n",
    "        \"per_class_auc\":  {l: (float(a) if not np.isnan(a) else None)\n",
    "                           for l, a in zip(LABELS, best4_pc)},\n",
    "        \"minority_avg\":   float(np.nanmean(m_aucs_4)),\n",
    "        \"minority_detail\":{ c: (float(a) if not np.isnan(a) else None)\n",
    "                            for c, a in zip(minority_classes, m_aucs_4)},\n",
    "    },\n",
    "    \"labels\": LABELS,\n",
    "}\n",
    "\n",
    "out_path = os.path.join(BASE_DIR, \"FINAL_4WAY_ENSEMBLE_RESULTS.json\")\n",
    "with open(out_path, \"w\") as f:\n",
    "    json.dump(final_results, f, indent=2)\n",
    "print(f\"\\n✅ Results saved → {out_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "56e44d13-78c6-498e-9337-b6fd4a672a29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving prediction CSVs...\n",
      "\n",
      "  Saved 25,596 rows → D:\\Major Project\\predictions_3way_ensemble.csv\n",
      "  Saved 25,596 rows → D:\\Major Project\\predictions_4way_ensemble.csv\n",
      "\n",
      "Sample (4-Way Ensemble, first 10 rows):\n",
      "     Image_Index Predicted_Label  Predicted_Confidence\n",
      "00000003_000.png          Hernia                0.8775\n",
      "00000003_001.png        Fibrosis                0.3004\n",
      "00000003_002.png          Hernia                0.7224\n",
      "00000003_003.png          Hernia                0.7286\n",
      "00000003_004.png          Hernia                0.7428\n",
      "00000003_005.png          Hernia                0.9085\n",
      "00000003_006.png          Hernia                0.8103\n",
      "00000003_007.png          Hernia                0.7416\n",
      "00000013_000.png    Cardiomegaly                0.3431\n",
      "00000013_001.png       Emphysema                0.7298\n"
     ]
    }
   ],
   "source": [
    "# CELL 16: Save per-image prediction CSVs for both ensembles\n",
    "\n",
    "def save_predictions_csv(preds, dataset, filename):\n",
    "    rows = []\n",
    "    for i in range(len(preds)):\n",
    "        row = {\"Image_Index\": dataset.df.iloc[i][\"Image_Index\"]}\n",
    "        for j, lbl in enumerate(LABELS):\n",
    "            row[lbl] = round(float(preds[i][j]), 4)\n",
    "        top_idx = int(np.argmax(preds[i]))\n",
    "        row[\"Predicted_Label\"]      = LABELS[top_idx]\n",
    "        row[\"Predicted_Confidence\"] = round(float(preds[i][top_idx]), 4)\n",
    "        rows.append(row)\n",
    "    df_out = pd.DataFrame(rows)\n",
    "    path   = os.path.join(BASE_DIR, filename)\n",
    "    df_out.to_csv(path, index=False)\n",
    "    print(f\"  Saved {len(df_out):,} rows → {path}\")\n",
    "    return df_out\n",
    "\n",
    "print(\"Saving prediction CSVs...\\n\")\n",
    "test_dataset = TEST_DL.dataset\n",
    "\n",
    "df_3way = save_predictions_csv(best3_preds, test_dataset, \"predictions_3way_ensemble.csv\")\n",
    "df_4way = save_predictions_csv(best4_preds, test_dataset, \"predictions_4way_ensemble.csv\")\n",
    "\n",
    "print(\"\\nSample (4-Way Ensemble, first 10 rows):\")\n",
    "print(df_4way[[\"Image_Index\",\"Predicted_Label\",\"Predicted_Confidence\"]]\n",
    "      .head(10).to_string(index=False))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f579b3d3-e395-479c-b962-4bda3155a38c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing optimal thresholds on validation set...\n",
      "\n",
      "Getting validation predictions...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  Preds: 100%|██████████████████████████████████████████████████| 1298/1298 [13:55<00:00,  1.55it/s]\n",
      "  Preds: 100%|██████████████████████████████████████████████████| 1298/1298 [09:11<00:00,  2.35it/s]\n",
      "  Preds: 100%|██████████████████████████████████████████████████| 1298/1298 [08:59<00:00,  2.41it/s]\n",
      "  Preds: 100%|██████████████████████████████████████████████████| 1298/1298 [10:22<00:00,  2.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  Disease                  Threshold    Val AUC\n",
      "  -----------------------------------------------\n",
      "  Atelectasis                 0.2662     0.7980\n",
      "  Consolidation               0.2190     0.8326\n",
      "  Infiltration                0.3030     0.6668\n",
      "  Pneumothorax                0.2048     0.8812\n",
      "  Edema                       0.1973     0.9425\n",
      "  Emphysema                   0.2064     0.9649\n",
      "  Fibrosis                    0.1925     0.9260\n",
      "  Effusion                    0.2973     0.8894\n",
      "  Pneumonia                   0.2196     0.9283\n",
      "  PleuralThickening              inf        nan\n",
      "  Cardiomegaly                0.2015     0.9370\n",
      "  Nodule                      0.2679     0.7451\n",
      "  Mass                        0.2451     0.8441\n",
      "  Hernia                      0.0153     0.9911\n",
      "\n",
      "✅ Thresholds saved → D:\\Major Project\\optimized_thresholds.json\n"
     ]
    }
   ],
   "source": [
    "# CELL 17: Per-class threshold optimisation via Youden's Index on validation set\n",
    "\n",
    "from sklearn.metrics import roc_curve\n",
    "\n",
    "print(\"Computing optimal thresholds on validation set...\\n\")\n",
    "\n",
    "@torch.no_grad()\n",
    "def get_preds(model, loader, use_meta=False):\n",
    "    model.eval()\n",
    "    all_labels, all_preds = [], []\n",
    "    for x, y, meta in tqdm(loader, desc=\"  Preds\", ncols=100):\n",
    "        x, meta = x.to(DEVICE), meta.to(DEVICE)\n",
    "        with torch.cuda.amp.autocast():\n",
    "            logits = model(x, meta) if use_meta else model(x, None)\n",
    "        all_labels.append(y.numpy())\n",
    "        all_preds.append(torch.sigmoid(logits).cpu().float().numpy())\n",
    "    return np.vstack(all_labels), np.vstack(all_preds)\n",
    "\n",
    "# Validation predictions for all 4 models\n",
    "print(\"Getting validation predictions...\")\n",
    "val_y, val_b0_p   = get_preds(model_b0,   VAL_DL, use_meta=False)\n",
    "_,     val_b3_p   = get_preds(model_b3,   VAL_DL, use_meta=False)\n",
    "_,     val_vit_p  = get_preds(model_vit,  VAL_DL, use_meta=False)\n",
    "_,     val_dino_p = get_preds(model_dino, VAL_DL, use_meta=True)\n",
    "\n",
    "wb0, wb3, wvit, wdino = best4_w\n",
    "val_ens = wb0*val_b0_p + wb3*val_b3_p + wvit*val_vit_p + wdino*val_dino_p\n",
    "\n",
    "# Youden's Index per class\n",
    "optimal_thresholds = {}\n",
    "print(f\"\\n  {'Disease':<22}  {'Threshold':>10}  {'Val AUC':>9}\")\n",
    "print(f\"  {'-'*47}\")\n",
    "for i, lbl in enumerate(LABELS):\n",
    "    fpr, tpr, thresholds = roc_curve(val_y[:, i], val_ens[:, i])\n",
    "    best_idx              = int(np.argmax(tpr - fpr))\n",
    "    best_thr              = float(thresholds[best_idx])\n",
    "    auc_val               = roc_auc_score(val_y[:, i], val_ens[:, i])\n",
    "    optimal_thresholds[lbl] = best_thr\n",
    "    print(f\"  {lbl:<22}  {best_thr:>10.4f}  {auc_val:>9.4f}\")\n",
    "\n",
    "thr_path = os.path.join(BASE_DIR, \"optimized_thresholds.json\")\n",
    "with open(thr_path, \"w\") as f:\n",
    "    json.dump(optimal_thresholds, f, indent=2)\n",
    "print(f\"\\n✅ Thresholds saved → {thr_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c17cb5d8-ca0a-49b7-8a4b-9db52c124ab5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing inference on:\n",
      "  D:\\Major Project\\chest_xray_data\\images_001\\images\\00000013_004.png\n",
      "\n",
      "\n",
      "Predictions → 00000013_004.png\n",
      "======================================================\n",
      "  Disease                   Prob     Thr  Result\n",
      "  --------------------------------------------------\n",
      "  Emphysema               0.6123  0.2064  POSITIVE ✅\n",
      "  Pneumothorax            0.4619  0.2048  POSITIVE ✅\n",
      "  Infiltration            0.3185  0.3030  POSITIVE ✅\n",
      "  Effusion                0.3149  0.2973  POSITIVE ✅\n",
      "  Atelectasis             0.3101  0.2662  POSITIVE ✅\n",
      "  Nodule                  0.2429  0.2679  negative\n",
      "  Mass                    0.2352  0.2451  negative\n",
      "  Consolidation           0.2306  0.2190  POSITIVE ✅\n",
      "  PleuralThickening       0.1944     inf  negative\n",
      "  Cardiomegaly            0.1202  0.2015  negative\n",
      "  Fibrosis                0.0867  0.1925  negative\n",
      "  Pneumonia               0.0809  0.2196  negative\n",
      "  Edema                   0.0570  0.1973  negative\n",
      "  Hernia                  0.0113  0.0153  negative\n",
      "\n",
      "  Detected: ['Emphysema', 'Pneumothorax', 'Infiltration', 'Effusion', 'Atelectasis', 'Consolidation']\n"
     ]
    }
   ],
   "source": [
    "# CELL 18: Single-image inference with 4-way ensemble + optimized thresholds\n",
    "\n",
    "def predict_single_image(image_path,\n",
    "                         patient_age=50,\n",
    "                         patient_gender=\"M\",\n",
    "                         view_position=\"PA\",\n",
    "                         followup=0):\n",
    "    transform = build_transforms(train=False)\n",
    "    img   = np.array(PILImage.open(image_path).convert(\"RGB\"))\n",
    "    img_t = transform(image=img)[\"image\"].unsqueeze(0).to(DEVICE)\n",
    "\n",
    "    age    = np.clip(patient_age, 0, 95) / 95.0\n",
    "    gender = {\"M\": 0.0, \"F\": 1.0}.get(patient_gender.upper(), 0.5)\n",
    "    view   = {\"PA\": 0.0, \"AP\": 1.0}.get(view_position.upper(), 0.5)\n",
    "    fup    = np.clip(followup / 10.0, 0, 1)\n",
    "    meta_t = torch.FloatTensor([[age, gender, view, fup]]).to(DEVICE)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        with torch.cuda.amp.autocast():\n",
    "            p_b0   = torch.sigmoid(model_b0(img_t,  None)).cpu().float().numpy()[0]\n",
    "            p_b3   = torch.sigmoid(model_b3(img_t,  None)).cpu().float().numpy()[0]\n",
    "            p_vit  = torch.sigmoid(model_vit(img_t, None)).cpu().float().numpy()[0]\n",
    "            p_dino = torch.sigmoid(model_dino(img_t, meta_t)).cpu().float().numpy()[0]\n",
    "\n",
    "    wb0, wb3, wvit, wdino = best4_w\n",
    "    probs = wb0*p_b0 + wb3*p_b3 + wvit*p_vit + wdino*p_dino\n",
    "\n",
    "    results = {}\n",
    "    for i, lbl in enumerate(LABELS):\n",
    "        prob = float(probs[i])\n",
    "        thr  = optimal_thresholds.get(lbl, 0.5)\n",
    "        results[lbl] = {\n",
    "            \"probability\": round(prob, 4),\n",
    "            \"threshold\":   round(thr, 4),\n",
    "            \"positive\":    bool(prob >= thr),\n",
    "        }\n",
    "\n",
    "    results = dict(sorted(results.items(),\n",
    "                          key=lambda x: x[1][\"probability\"], reverse=True))\n",
    "\n",
    "    print(f\"\\nPredictions → {os.path.basename(image_path)}\")\n",
    "    print(f\"{'='*54}\")\n",
    "    print(f\"  {'Disease':<22}  {'Prob':>6}  {'Thr':>6}  {'Result'}\")\n",
    "    print(f\"  {'-'*50}\")\n",
    "    for lbl, info in results.items():\n",
    "        result_str = \"POSITIVE ✅\" if info[\"positive\"] else \"negative\"\n",
    "        print(f\"  {lbl:<22}  {info['probability']:>6.4f}  \"\n",
    "              f\"{info['threshold']:>6.4f}  {result_str}\")\n",
    "\n",
    "    positives = [l for l, v in results.items() if v[\"positive\"]]\n",
    "    print(f\"\\n  Detected: {positives if positives else ['No Finding']}\")\n",
    "    return results\n",
    "\n",
    "\n",
    "# Test on a random image from the dataset\n",
    "from PIL import Image as PILImage\n",
    "sample_img = list(IMAGE_MAP.values())[42]\n",
    "print(f\"Testing inference on:\\n  {sample_img}\\n\")\n",
    "_ = predict_single_image(sample_img, patient_age=58,\n",
    "                          patient_gender=\"M\", view_position=\"PA\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "25bec751-157e-46ed-be95-755da9c08d56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Loaded 10 epochs from D:\\Major Project\\phase7_dinov2_results.json\n",
      "\n",
      "  Epoch  1  |  Train Loss 0.0075  AUC 0.5762  |  Val Loss 0.0023  AUC 0.7262\n",
      "  Epoch  2  |  Train Loss 0.0038  AUC 0.7213  |  Val Loss 0.0017  AUC 0.7701\n",
      "  Epoch  3  |  Train Loss 0.0033  AUC 0.7746  |  Val Loss 0.0019  AUC 0.7741\n",
      "  Epoch  4  |  Train Loss 0.0029  AUC 0.8118  |  Val Loss 0.0018  AUC 0.7776\n",
      "  Epoch  5  |  Train Loss 0.0025  AUC 0.8389  |  Val Loss 0.0017  AUC 0.7835\n",
      "  Epoch  6  |  Train Loss 0.0022  AUC 0.8592  |  Val Loss 0.0020  AUC 0.7763\n",
      "  Epoch  7  |  Train Loss 0.0019  AUC 0.8717  |  Val Loss 0.0021  AUC 0.7762\n",
      "  Epoch  8  |  Train Loss 0.0018  AUC 0.8826  |  Val Loss 0.0021  AUC 0.7703\n",
      "  Epoch  9  |  Train Loss 0.0016  AUC 0.8905  |  Val Loss 0.0023  AUC 0.7721\n",
      "  Epoch 10  |  Train Loss 0.0015  AUC 0.8972  |  Val Loss 0.0024  AUC 0.7717\n",
      "\n",
      "✅ Training curves saved → D:\\Major Project\\phase7_dinov2_training_curves.png\n"
     ]
    }
   ],
   "source": [
    "# CELL 19 FIXED: Load dino_history from saved JSON, then plot curves\n",
    "\n",
    "import json\n",
    "import matplotlib\n",
    "matplotlib.use(\"Agg\")\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# ── Load history from disk (saved at end of Cell 12) ──────────────────────\n",
    "history_path = os.path.join(BASE_DIR, \"phase7_dinov2_results.json\")\n",
    "\n",
    "with open(history_path, \"r\") as f:\n",
    "    dino_history = json.load(f)\n",
    "\n",
    "print(f\"✅ Loaded {len(dino_history)} epochs from {history_path}\\n\")\n",
    "for h in dino_history:\n",
    "    print(f\"  Epoch {h['epoch']:>2}  |  \"\n",
    "          f\"Train Loss {h['train_loss']:.4f}  AUC {h['train_auc']:.4f}  |  \"\n",
    "          f\"Val Loss {h['val_loss']:.4f}  AUC {h['val_auc']:.4f}\")\n",
    "\n",
    "# ── Plot ───────────────────────────────────────────────────────────────────\n",
    "epochs     = [h[\"epoch\"]      for h in dino_history]\n",
    "train_aucs = [h[\"train_auc\"]  for h in dino_history]\n",
    "val_aucs   = [h[\"val_auc\"]    for h in dino_history]\n",
    "train_loss = [h[\"train_loss\"] for h in dino_history]\n",
    "val_loss   = [h[\"val_loss\"]   for h in dino_history]\n",
    "\n",
    "best_val   = max(val_aucs)\n",
    "best_epoch = epochs[val_aucs.index(best_val)]\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# AUC plot\n",
    "axes[0].plot(epochs, train_aucs, \"b-o\", label=\"Train AUC\")\n",
    "axes[0].plot(epochs, val_aucs,   \"r-o\", label=\"Val AUC\")\n",
    "axes[0].axvline(x=best_epoch, color=\"green\", linestyle=\"--\",\n",
    "                label=f\"Best epoch {best_epoch}\")\n",
    "axes[0].axhline(y=best3_auc,  color=\"purple\", linestyle=\":\",\n",
    "                label=f\"3-Way Ens {best3_auc:.4f}\")\n",
    "axes[0].axhline(y=best4_auc,  color=\"orange\", linestyle=\":\",\n",
    "                label=f\"4-Way Ens {best4_auc:.4f}\")\n",
    "axes[0].set_title(\"DINOv2 — AUC per Epoch\")\n",
    "axes[0].set_xlabel(\"Epoch\")\n",
    "axes[0].set_ylabel(\"AUC (macro)\")\n",
    "axes[0].legend(fontsize=8)\n",
    "axes[0].grid(True)\n",
    "axes[0].set_xticks(epochs)\n",
    "\n",
    "# Loss plot\n",
    "axes[1].plot(epochs, train_loss, \"b-o\", label=\"Train Loss\")\n",
    "axes[1].plot(epochs, val_loss,   \"r-o\", label=\"Val Loss\")\n",
    "axes[1].axvline(x=best_epoch, color=\"green\", linestyle=\"--\",\n",
    "                label=f\"Best epoch {best_epoch}\")\n",
    "axes[1].set_title(\"DINOv2 — Focal Loss per Epoch\")\n",
    "axes[1].set_xlabel(\"Epoch\")\n",
    "axes[1].set_ylabel(\"Focal Loss\")\n",
    "axes[1].legend(fontsize=8)\n",
    "axes[1].grid(True)\n",
    "axes[1].set_xticks(epochs)\n",
    "\n",
    "plt.suptitle(\n",
    "    f\"Phase 7 DINOv2 Training  |  \"\n",
    "    f\"Best Val AUC: {best_val:.4f} (Epoch {best_epoch})  |  \"\n",
    "    f\"4-Way Ensemble: {best4_auc:.4f}\",\n",
    "    fontsize=12\n",
    ")\n",
    "plt.tight_layout()\n",
    "\n",
    "fig_path = os.path.join(BASE_DIR, \"phase7_dinov2_training_curves.png\")\n",
    "plt.savefig(fig_path, dpi=150, bbox_inches=\"tight\")\n",
    "plt.close()\n",
    "print(f\"\\n✅ Training curves saved → {fig_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80092b2a-180c-4de7-9bbf-c9b864ec1ea8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (chest_xray_clean)",
   "language": "python",
   "name": "chest_xray_clean"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
